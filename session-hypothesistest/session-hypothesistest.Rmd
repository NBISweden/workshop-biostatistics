---
title: "Hypothesis tests"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
require(kableExtra)
library(reshape2)
library(ggplot2)
require(knitr)
require(UsingR)
knitr::opts_chunk$set(fig.width=3.5, fig.height=3.5, echo = FALSE, cache=TRUE, error=FALSE, warnings=FALSE)
```

### Learning outcome

- define null and alternative hypothesis
- perform a hypothesis tests using resampling (e.g. permutation test)
- perform a t-test

# Hypothesis test
 
In a hypothesis test a hypothesis is evaluated based on a random sample.

The hypothesis that are tested are assumptions about properties of the population, such as proportion, mean, mean difference etc.

## The null and alternative hypothesis

There are two hypotheses involved in a hypothesis test, the null hypothesis ($H_0$) and the alternative hypothesis ($H_1$).

The null hypothesis is in general neutral, "no change", "no difference between groups", "no association". In general we want to show that $H_0$ is false.

The alternative hypothesis expresses what the researcher is interested in "the treatment has an effect", "there is a difference between groups", "there is an association". The alternative hypothesis can also be directional "the treatment has a positive effect".

## To perform a hypothesis test

1. Define $H_0$ and $H_1$
2. Assume that the $H_0$ is true and compute the sampling distribution.
3. Compare the observed value with the computed sample distribution under $H_0$ and compute a p-value. The p-value is the probability of observing a value at least as extreme as the observed value, if $H_0$ is true.
4. Based on the p-value either accept $H_0$ or reject $H_0$.

# One sample, proportions
## Pollen example

Remember out pollen example. Let's assume we know that the proportion of pollen allergy in the Sweden population is $0.3$. We suspect that the number of pollen allergic has increased in Uppsala in the last couple of year adn want to investigate this.

Observe 100 people, 42 of these were allergic to pollen. Is there a reason to belive that the proportion $\pi >0.3$?


$$H_0:\, \pi=\pi_0$$

$$H_1:\, \pi>\pi_0$$

In our example $\pi_0=0.3$.


Remember the sample distribution

```{r, out.width="50%", fig.align="center"}
set.seed(13)
p <- replicate(100000, mean(sample(0:1, 100, p=c(.7,.3), replace=TRUE)))
ggplot(data.frame(p=p), aes(x=p)) + geom_histogram(color="white", binwidth=0.02) + geom_vline(xintercept=0.42, color="red") + theme_bw()
```
## The p-value

The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.

Use the sampling distribution to calculate the p-value

$$P(P \geq 0.42|H_0)$$

$$P(P \geq 0.42|H_0) = `r mean(p>=0.42)`$$


## Parametric test

If $H_0$ is true $\pi=\pi_0=0.3$ and approximately

$$P \sim N\left(\pi_0, \sqrt{\frac{\pi_0(1-\pi_0)}{n}}\right)$$
Test statistic $$Z = \frac{P-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}$$

Replace $P$ with our observed value $p=0.42$ and compute our observed
$$Z_{obs} = \frac{0.42-0.3}{\sqrt{\frac{0.3(1-0.3)}{100}}} = `r zobs <- (.42-.3)/sqrt(.3*.7/100);format(zobs, digits=3)`$$

# The p-value

The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.

$$p = P(P\geq\pi_0) = P(P \geq 0.42) = P(Z>z_{obs}) = P(Z>`r format(zobs, digits=3)`) = [table] =  `r sprintf("%.4f", pnorm(zobs, lower.tail=FALSE))`$$

Conclusion?

Significance level

Direction of the test

# Two samples, mean difference
## Example: Do high fat diet lead to increased body weight?

Study setup:

1. Order 24 female mice from a lab.
2. Randomly assign 12 of the 24 mice to receive high-fat diet, the
  remaining 12 are controls (ordinary diet).
3. Measure body weight after one week.

### The null and alternative hypothesis

$$
\begin{aligned}
H_0: \mu_2 = \mu_1 \iff \mu_2 - \mu_1 = 0\\
H_1: \mu_2>\mu_1 \iff \mu_2-\mu_1 > 0
\end{aligned}
$$

where $\mu_2$ is the (unknown) mean body weight of the high-fat mouse population and $\mu_1$ is the mean body-weight of the control mouse population.

In words;

$H_0$: high-fat diet has no effect on mice weight

$H_1$: high-fat diet result in heavier mice compared to ordinary diet

Studied population: Female mice that can be ordered from a lab.

```{r mice, echo=TRUE}
## Download the mouse population
mp <- read.csv("https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv")
## Select all female mice
pop.F <- mp %>% filter(Sex=="F")
## Select all the female mice on high fat diet
pop.F.hf <- (pop.F %>% filter(Diet=="hf"))[, "Bodyweight"]
## Select all the female mice on ordinary diet
pop.F.n <- (pop.F %>% filter(Diet=="chow"))[, "Bodyweight"]
```

### Observation

```{r miceobs, echo=TRUE}
## Select the seed so that we all get the same random mice!
set.seed(1)
## Select 12 HF mice
xHF <- sample(pop.F.hf, 12)
## Select 12 O mice
xN <- sample(pop.F.n, 12)
```

```{r}
kable(rbind("high-fat"=xHF, "ordinary"=xN), digits=1) %>% kable_styling(font_size=10)
```

```{r }
##Compute mean body weights of the two samples
mHF <- mean(xHF)
mN <- mean(xN)
## Compute mean difference
dobs <- mHF - mN
```

Mean weight of control mice (ordinary diet): $\bar x_1 = `r sprintf("%.2f", mN)`$

Mean weight of mice on high-fat diet: $\bar x_2 = `r sprintf("%.2f", mHF)`$

Difference in mean weights: $d = \bar x_2 - \bar x_1 = `r dobs`$


### Sampling distribution under $H_0$

Mean weight of 12 (randomly selected) mice on ordinary diet, $\bar X_1$. $E[\bar X_1] = E[X_1] = \mu_1$
  
Mean weight of 12 (randomly selected) mice on high-fat diet, $\bar X_2$. $E[\bar X_2] = E[X_2] = \mu_2$

The mean difference is also a random variable: $D = \bar X_2 - \bar X_1$
  
If high-fat diet has no effect, i.e. if $H_0$ was true, the result would be as if all mice were given the ordinary diet. What can we expect if all mice are fed with the ordinary food? The 24 mice were initially from the same population, depending on how the mice are randomly assigned to high-fat and normal group, the mean weights would differ.

Assume $H_0$ is true, i.e. assume all mice are equivalent and
  
1. Randomly reassign 12 of the 24 mice to 'high-fat' and the remaining 12 to 'control'.
2. Compute difference in mean weights

If we repeat 1-2 many times we get the sampling distribution when $H_0$ is true, the so called null distribution, of difference in mean weights.


```{r permtest, echo=TRUE}
## All 24 body weights in a vector
x <- c(xHF, xN)
## Mean difference
dobs <- mean(x[1:12]) - mean(x[13:24])
dobs
## Permute
y <- sample(x)
##Mean difference
mean(y[1:12]) - mean(y[13:24])
dnull.perm <- replicate(n = 100000, {
  y <- sample(x)
  ##Mean difference
  mean(y[1:12]) - mean(y[13:24])
})
ggplot(data.frame(d=dnull.perm), aes(x=d)) + geom_histogram(bins=25, color="white") + theme_bw() + geom_vline(xintercept=dobs, color="red")
## Compute the p-value
mean(dnull.perm>dobs)
```


### p-value

What is the probability to get an at least as extreme mean difference as our observed value, $d_{obs}$, if $H_0$ was true?

$$P(\bar X_2 - \bar X_2 \geq d_{obs} | H_0) = `r sprintf("%.3g",mean(dnull.perm>=dobs))`$$

## Parametric tests


### Two samples, known $\sigma_1$ and $\sigma_2$

$$H_0: \mu_2 = \mu_1\\
H_1: \mu_2>\mu_1$$

Lets assume that both the control and treatment populations are normally distributed, with unknown mean, but known standard deviations, $\sigma_1=3.4$ and $\sigma_2=5.1$.

$$X_1 \sim N(\mu_1, \sigma_1) \\
X_2 \sim N(\mu_2, \sigma_2)$$

If follows that the sample means are 

$$\bar X_1 \sim N(\mu_1, \sigma_1/\sqrt{n_1}) \\
\bar X_2 \sim N(\mu_2, \sigma_2/\sqrt{n_2})$$

The mean difference $D = \bar X_2 - \bar X_1$ is thus also normally distributed:

$$D = \bar X_2 - \bar X_1 = N(\mu_2-\mu_1, \sqrt{\sigma_2^2/\sqrt{n_2} + \sigma_1^2/\sqrt{n_1}})$$

If $H_0$ is true: $\bar X_2 - \bar X_1 = N(0, \sqrt{\sigma_2^2/\sqrt{n_2} + \sigma_1^2/\sqrt{n_1}})$

The test statistic: $$Z = \frac{\bar X_2 - \bar X_1 - 0}{\sqrt{\sigma_2^2/\sqrt{n_2} + \sigma_1^2/\sqrt{n_1}}}$$ is standard normal, i.e. $Z \sim N(0,1)$.

The observed value of the test statistic:
$$Z_{obs} = \frac{m_2-m_1}{\sqrt{\sigma_2^2/\sqrt{n_2} + \sigma_1^2/\sqrt{n_1}}}$$
$$Z_{obs} = \frac{`r mHF` - `r mN`}{\sqrt{5.1^2/12 + 3.4^2/12}} = `r zobs=(mHF-mN)/sqrt(5.1^2/12+3.4^2/12); zobs`$$

$$P(\bar X_2 - \bar X_1 > d_{obs}) = P(Z>Z_{obs}) = 1 - P(Z<Z_{obs}) = 1 - P(Z<`r zobs`) = [table] = `r format(1-pnorm(zobs))`$$

```{r echo=TRUE}
## Our observed value
dobs
## The p-value
1-pnorm(dobs, mean=0, sd=sqrt(5.1^2/12 + 3.4^2/12))
1-pnorm((dobs-0)/sqrt(5.1^2/12 + 3.4^2/12))
pnorm(dobs, mean=0, sd=sqrt(5.1^2/12 + 3.4^2/12), lower.tail=FALSE)
pnorm((dobs-0)/sqrt(5.1^2/12 + 3.4^2/12), lower.tail=FALSE)
```

### Two samples, unknown standard deviations

What if the population standard deviations are not known?

If the sample sizes are large, we can replace the known standard deviations with out sample standard deviations and according to the central limit theorem assume that 

$$Z = \frac{\bar X_2 - \bar X_1}{\sqrt{s_2^2/\sqrt{n_2} + s_1^2/\sqrt{n_1}}} \ sim N(0,1)$$
and procede as before.

Here $n_1=n_2=12$ which is not very large.

For small sample sizes we can use Student's t-test, which requires us to assume that $X_1$ and $X_2$ are both normally distributed and have equal variances. With these assumptions we can compute the pooled variance

$$s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}$$
and the test statistic

$$t = \frac{\bar X_1 - \bar X_2 - 0}{\sqrt{s_p^2(\frac{1}{n_1} + \frac{1}{n_2})}}$$

$t$ is t-distributed with $n_1+n_2-1$ degrees of freedom.

The t-test is implemented in R.

```{r ttest, echo=TRUE}
# Student's t-test with pooled variances
t.test(xHF, xN, var.equal=TRUE, alternative="greater")
# Unequal variances with Welch approximation to the degrees of freedom (the default)
t.test(xHF, xN, var.equal=FALSE, alternative="greater")
```

