<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Regression session II: multiple linear regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Warren W. Kretzschmar" />
    <meta name="date" content="2019-05-19" />
    <link href="session-regression-II-slides_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="session-regression-II-slides_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Regression session II: multiple linear regression
### Warren W. Kretzschmar
### 2019-05-19

---





class: middle, center

# Warmup quiz: revisiting linear model specifications

https://forms.gle/z4qKdrcQj1wqUxBV7

![Revisiting linear model specefications form](./assets/qrcode.quiz-revisiting.png)

---

# Visualizing the Advertising dataset

Get it from the workshop directory on github: `./session-regression-II/data/Advertising.csv`

- Sales for 200 products
- Advertizing money spent on TV, radio, and newspaper ads

.center[How can we best spend advertizing money to maximize sales?]

--

## Live coding demo: Visualize the Advertising dataset and fit simple linear regressions

???


```r
# load the data
ads = read.csv('./data/Advertising.csv')
```

First, we check to see what columns were imported


```r
head(ads)
```

```
##   X    TV radio newspaper sales
## 1 1 230.1  37.8      69.2  22.1
## 2 2  44.5  39.3      45.1  10.4
## 3 3  17.2  45.9      69.3   9.3
## 4 4 151.5  41.3      58.5  18.5
## 5 5 180.8  10.8      58.4  12.9
## 6 6   8.7  48.9      75.0   7.2
```

It looks like a redundant column of row numbers, `X`, has made it into the table.

The other columns look like numbers. That's good.

Now, let us use the `pairs` function to get a quick overview of linear relationships within the dataset. 


```r
# visualize all pairwise relationships
pairs(ads)
```

![](session-regression-II-files/figures/unnamed-chunk-3-1.png)&lt;!-- --&gt;

The pairs plot creates a scatter plot of every pair of variables in a data frame.
First, to clear things up, the variable `X` is uncorrelated with the other columns and does not 
add anything to the dataset. We should probably remove it and replot:


```r
ads = ads[-1]
pairs(ads)
```

![](session-regression-II-files/figures/unnamed-chunk-4-1.png)&lt;!-- --&gt;

Ah, that's better.

From the pairs plot we can see that:

1. TV expenditure appears to be correlated with sales
2. As TV expenditure goes up, the variance associated with sales increases as well
3. radio expenditure appears to be correlated with sales
4. newspaper sales do not look very correlated to sales

It looks like more than one variable could be used to predict sales. 
How would we handle this in the simple regression? 

## Excercise: fitting simple linear regressions on multivariate data

We can fit a simple linear regression for TV vs Sales this way:

```r
lm(Sales ~ TV, data=ads)
```

```
## Error in eval(predvars, data, env): object 'Sales' not found
```

Oops that did not work! Let's see what's up:


```r
names(ads)
```

```
## [1] "TV"        "radio"     "newspaper" "sales"
```
Ah! sales is lower case:

```r
lm(sales ~ TV, data=ads)
```

```
## 
## Call:
## lm(formula = sales ~ TV, data = ads)
## 
## Coefficients:
## (Intercept)           TV  
##     7.03259      0.04754
```
For every \$1000 spent on TV ads, our average sales went up by five units.
Pretty sweet! What about radio?


```r
lm(sales ~ radio, data=ads)
```

```
## 
## Call:
## lm(formula = sales ~ radio, data = ads)
## 
## Coefficients:
## (Intercept)        radio  
##      9.3116       0.2025
```
radio appears to help even more!


```r
lm(sales ~ newspaper, data=ads)
```

```
## 
## Call:
## lm(formula = sales ~ newspaper, data = ads)
## 
## Coefficients:
## (Intercept)    newspaper  
##    12.35141      0.05469
```
newspaper appears to have a similar effect to TV. 
But there seemed to be much more noise between sales and newspaper in the pairs plot.  What's going on?


```r
summary(lm(sales ~ TV, data=ads))
```

```
## 
## Call:
## lm(formula = sales ~ TV, data = ads)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3860 -1.9545 -0.1913  2.0671  7.2124 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
## TV          0.047537   0.002691   17.67   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.259 on 198 degrees of freedom
## Multiple R-squared:  0.6119,	Adjusted R-squared:  0.6099 
## F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16
```

```r
summary(lm(sales ~ newspaper, data=ads))
```

```
## 
## Call:
## lm(formula = sales ~ newspaper, data = ads)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.2272  -3.3873  -0.8392   3.5059  12.7751 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 12.35141    0.62142   19.88  &lt; 2e-16 ***
## newspaper    0.05469    0.01658    3.30  0.00115 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.092 on 198 degrees of freedom
## Multiple R-squared:  0.05212,	Adjusted R-squared:  0.04733 
## F-statistic: 10.89 on 1 and 198 DF,  p-value: 0.001148
```
The answer is in the `\(R^2\)` values: TV has a much higher `\(R^2\)` than newspaper.

---

# Fitting simple linear regressions wrapup

Two problems remain:

1. Process for combining three models for prediction? 
2. Inferrential problems when predictors are correlated.

Multiple linear regression solves these problems.

---

# Multiple linear regression model specifications

`$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_p + \epsilon$$`

- `\(Y\)`: response variable
- `\(X_j\)`: predictor variables
- `\(\beta_j\)`: model coefficients
- `\(\epsilon\)`: noise term

--

`\(\beta_j\)` can be interpreted as the average
increase in `\(Y\)` for one unit increase in `\(X_j\)` while holding all other predictors fixed.

--

An example regression model for the `Advertising` dataset:

`$$Sales = \beta_0 + \beta_1 newspaper + \beta_2 radio + \beta_3 TV + \epsilon$$`

---

# Estimating regression coefficients

`$$\hat{y} = \hat\beta_0 + \hat\beta_1x_1 + ... + \hat\beta_px_p$$`

- `\(\hat{y}\)`: estimated value
- `\(\hat{\beta_j}\)`: estimated regression coefficient

--

We choose `\(\beta_j\)` to minimize the residual sum of squares:

`$$\text{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i)^2$$`

--

`$$\text{RSS} = \sum_{i=1}^n (y_i - \hat\beta_0 - \hat\beta_1x_{i1} - ... - \hat\beta_px_{ip})^2$$`

???
The mathematical formulas for estimating the model coefficients in multiple linear regression
work similarly to the formulas for simple linear regression. However, they are more complex and 
require some linear algebra to understand, so we will skip those formulas here. 

---

class: middle, center

# Quiz: What was `\(y_i\)` again?

https://forms.gle/XUxpgxJbkTp1QfDG8

![What was y_i again?](./assets/qrcode.what_was_yi.png)

---

class: center, middle

# Live coding demo: Fitting a multiple linear regression model

???

Above, we fit a simple linear regression model to the Advertising dataset.
We had to fit each predictor separately. Here we will fit a joint
model:


```r
summary(lm(sales ~ TV + newspaper + radio, data=ads))
```

```
## 
## Call:
## lm(formula = sales ~ TV + newspaper + radio, data = ads)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.8277 -0.8908  0.2418  1.1893  2.8292 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
## TV           0.045765   0.001395  32.809   &lt;2e-16 ***
## newspaper   -0.001037   0.005871  -0.177     0.86    
## radio        0.188530   0.008611  21.893   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.686 on 196 degrees of freedom
## Multiple R-squared:  0.8972,	Adjusted R-squared:  0.8956 
## F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16
```

We note that the coefficient estimates have changed! TV looks similar 
to what we saw in simple linear regression, but newspaper and radio have
both decreased. This is expected when predictors are correlated.
The multiple linear regression fit takes the correlation between predictors 
into account. This fit states that once we take TV and radio into account, newspaper 
ads do not increase sales.

---

# Questions we can answer with a multiple linear regression

1. Can any of the predictors predict response?
2. If so, to what degree are the predictors important?
3. How well does the model explain the data?
4. What is the model's prediction accuracy?

---

# Can any of the predictors predict response?

## Null hypothesis

`$$H_0: \beta_0 = \beta_1 = ... = \beta_p = 0$$`

--

## Alternate hypothesis

`$$H_A: \text{at least one } \beta_j \text{ is not 0}$$`

---

# The `\(F\)`-test

- named in honor of R. A. Fisher
- uses the `\(F\)`-statistic:

`$$F = \frac{\text{explained variance}}{\text{unexplained variance}}$$`

???

In a model in which our assumptions hold, and for which our null hypothesis is true, 
we expect the explained and unexplained variances to be equal. Therefore, under the 
null hypothesis, the `\(F\)`-statistic should be around 1.

---

# Estimating explained variance

`$$\frac{TSS-RSS}{p}$$`

- TSS: total sum of squares
- RSS: residual sum of squares

# Estimating unexplained variance

`$$\frac{RSS}{(n-p-1)}$$`

???

For any model, as we increase the number of predictors the
amount of variance that we explain with our model increases. 
The denominator, `\(p\)`, corrects for this.

As with the explained variance above, `\(p\)` in this denominator corrects for 
how unexplained variance decreases as we add more predictors. We can also see
that as our sample size, `\(n\)`, increases, our RSS increases as well.

---

class: middle

# The `\(F\)`-statistic for a linear model

`$$F = \left. {\color{cyan}{\frac{(TSS - RSS)}{p}}} \middle/ {\color{magenta}{\frac{RSS}{(n-p-1)}}} \right.$$`

- `\(\color{cyan}{\text{explained variance}}\)`
- `\(\color{magenta}{\text{unexplained variance}}\)`

???

If our null hypothesis is not true, then, assuming that the `\(TSS\)` remains constant,
we can expect the `\(RSS\)` to become smaller compared to the `\(TSS\)`, and
for the ratio to increase. Therefore, the larger the `\(F\)`-statistic, the more evidence there is for
rejecting the null hypothesis.

`R` will happily calculate the `\(F\)`-statistic of a linear model fit for us. One way to get the
`\(F\)` statistic is using the `summary()` function:


```r
summary(lm(sales ~ TV + newspaper + radio, data=ads))
```

```
## 
## Call:
## lm(formula = sales ~ TV + newspaper + radio, data = ads)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.8277 -0.8908  0.2418  1.1893  2.8292 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
## TV           0.045765   0.001395  32.809   &lt;2e-16 ***
## newspaper   -0.001037   0.005871  -0.177     0.86    
## radio        0.188530   0.008611  21.893   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.686 on 196 degrees of freedom
## Multiple R-squared:  0.8972,	Adjusted R-squared:  0.8956 
## F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16
```

In this case, the `\(F\)`-statistic is 570. That looks like a lot, and the low
`\(p\)`-value confirms that it is.

### Excercise: playing around with `\(n\)`

We can get an idea of how sample size changes the `\(F\)`-statistic and the 
`\(p\)`-value associated with the statistic. 

We can use `sample()` to reduce the sample size:


```r
?sample
```

We want to be sure to sample without replacement, and the help page tells us that this is the default


```r
summary(lm(sales ~ TV + newspaper + radio, data=ads[sample(nrow(ads), 200),]))
```

```
## 
## Call:
## lm(formula = sales ~ TV + newspaper + radio, data = ads[sample(nrow(ads), 
##     200), ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.8277 -0.8908  0.2418  1.1893  2.8292 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
## TV           0.045765   0.001395  32.809   &lt;2e-16 ***
## newspaper   -0.001037   0.005871  -0.177     0.86    
## radio        0.188530   0.008611  21.893   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.686 on 196 degrees of freedom
## Multiple R-squared:  0.8972,	Adjusted R-squared:  0.8956 
## F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16
```

```r
summary(lm(sales ~ TV + newspaper + radio, data=ads[sample(nrow(ads), 50),]))
```

```
## 
## Call:
## lm(formula = sales ~ TV + newspaper + radio, data = ads[sample(nrow(ads), 
##     50), ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.0883 -0.8725  0.4074  1.1872  3.1664 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 3.421015   0.773277   4.424 5.89e-05 ***
## TV          0.040918   0.003557  11.504 3.93e-15 ***
## newspaper   0.024861   0.016109   1.543     0.13    
## radio       0.177333   0.019388   9.146 6.42e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.932 on 46 degrees of freedom
## Multiple R-squared:  0.8502,	Adjusted R-squared:  0.8404 
## F-statistic: 87.01 on 3 and 46 DF,  p-value: &lt; 2.2e-16
```

```r
summary(lm(sales ~ TV + newspaper + radio, data=ads[sample(nrow(ads), 10),]))
```

```
## 
## Call:
## lm(formula = sales ~ TV + newspaper + radio, data = ads[sample(nrow(ads), 
##     10), ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.3508 -0.6891  0.1090  0.6101  1.4120 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.819620   0.955861   3.996  0.00715 ** 
## TV           0.059749   0.005062  11.803 2.24e-05 ***
## newspaper   -0.025871   0.017123  -1.511  0.18157    
## radio        0.154182   0.028106   5.486  0.00154 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.065 on 6 degrees of freedom
## Multiple R-squared:  0.9818,	Adjusted R-squared:  0.9728 
## F-statistic: 108.1 on 3 and 6 DF,  p-value: 1.301e-05
```

It looks like the signal is very strong, and we can still reject our null hypothesis 
with 10 data points.

The model summaries have p-values next to each model coefficient. 
These p-values are based on the `\(t\)`-statistic and are calculated in the same way as 
for simple linear regression (see previous section). 
Why can't we just use these p-values instead of the `\(F\)`-statistic to determine
if any coefficients are non-zero? 
Without correction for multiple testing we will get false positives at the probability of
`\(\alpha\)` per test.
If we do correct for multiple testing, then the `\(F\)`-test is more powerful and/or
requires fewer assumptions about the correlation structure of the `\(t\)`-statistics.

## Which predictors predict response?

Usually, we will not want to include all possible predictors in our model. 
But how can we choose the predictors? We could use the `\(t\)`-test, but then 
we will have to deal with false positives. The process of choosing predictors
in this way is called *variable selection*. There is a substantial body of 
literature on variable selection in linear models.

Out of all possible models, we would like to choose the one that is closest
to the true model. We face two problems in this endeavor:

1. Determining which model fits best while correcting for multiple testing and overfitting
2. The number of models that can be created from a subset of `\(p\)` predictors is
   `\(2^p\)`, and this number can get large very quickly.

For point one there are several statistics that can be used. These statistics
include *Mallow's C*, *Akaike's Information Criterion* (AIC), 
and the *Bayesian Information Criterion* (BIC). These statistics balance the number 
of predictors used against the amount of variance explained by a model.

For point two we can use a step-wise selection process in which we add, remove,
or add and remove
predictors in order to minimize an information criterion. This approach does not
explore the full model space, but in practice it can be quite useful.

### Exercise: Let's select predictors in a model

The `stepAIC()` function can be used to perform step-wise model selection in `R`.
By default it uses AIC, but other statistics are also supported.

We can start with the full model:

```r
library(MASS)
full = lm(sales ~ TV + newspaper + radio, data=ads)
summary(stepAIC(full))
```

```
## Start:  AIC=212.79
## sales ~ TV + newspaper + radio
## 
##             Df Sum of Sq    RSS    AIC
## - newspaper  1      0.09  556.9 210.82
## &lt;none&gt;                    556.8 212.79
## - radio      1   1361.74 1918.6 458.20
## - TV         1   3058.01 3614.8 584.90
## 
## Step:  AIC=210.82
## sales ~ TV + radio
## 
##         Df Sum of Sq    RSS    AIC
## &lt;none&gt;                556.9 210.82
## - radio  1    1545.6 2102.5 474.52
## - TV     1    3061.6 3618.5 583.10
```

```
## 
## Call:
## lm(formula = sales ~ TV + radio, data = ads)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.7977 -0.8752  0.2422  1.1708  2.8328 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
## TV           0.04575    0.00139  32.909   &lt;2e-16 ***
## radio        0.18799    0.00804  23.382   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.681 on 197 degrees of freedom
## Multiple R-squared:  0.8972,	Adjusted R-squared:  0.8962 
## F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16
```

This returns a model in which newspaper (unsurprisingly) has been removed.

Or we can start with an empty model:


```r
empty = lm(sales ~ 1, data=ads)
summary(stepAIC(empty, scope=sales ~ TV + newspaper + radio))
```

```
## Start:  AIC=661.8
## sales ~ 1
## 
##             Df Sum of Sq    RSS    AIC
## + TV         1    3314.6 2102.5 474.52
## + radio      1    1798.7 3618.5 583.10
## + newspaper  1     282.3 5134.8 653.10
## &lt;none&gt;                   5417.1 661.80
## 
## Step:  AIC=474.52
## sales ~ TV
## 
##             Df Sum of Sq    RSS    AIC
## + radio      1    1545.6  556.9 210.82
## + newspaper  1     184.0 1918.6 458.20
## &lt;none&gt;                   2102.5 474.52
## - TV         1    3314.6 5417.1 661.80
## 
## Step:  AIC=210.82
## sales ~ TV + radio
## 
##             Df Sum of Sq    RSS    AIC
## &lt;none&gt;                    556.9 210.82
## + newspaper  1      0.09  556.8 212.79
## - radio      1   1545.62 2102.5 474.52
## - TV         1   3061.57 3618.5 583.10
```

```
## 
## Call:
## lm(formula = sales ~ TV + radio, data = ads)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.7977 -0.8752  0.2422  1.1708  2.8328 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
## TV           0.04575    0.00139  32.909   &lt;2e-16 ***
## radio        0.18799    0.00804  23.382   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.681 on 197 degrees of freedom
## Multiple R-squared:  0.8972,	Adjusted R-squared:  0.8962 
## F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16
```

And in this case we get the same model as above.

## How well does the model explain the data?

As in simple linear regression, two important statistics for assessing the
quality of the model fit are `\(R^2\)` and RSE. 

### `\(R^2\)`

- In simple linear linear regression: `\(R^2 = \text{Cor}(X, Y)^2\)`
- In multiple linear regression: `\(R^2 = \text{Cor}(Y, \hat{Y})\)`

Let's see what the `\(R^2\)` of our models look like:


```r
summary(lm(sales ~ TV , data=ads))$r.squared
```

```
## [1] 0.6118751
```

```r
summary(lm(sales ~ TV + radio, data=ads))$r.squared
```

```
## [1] 0.8971943
```

```r
summary(lm(sales ~ TV + radio + newspaper, data=ads))$r.squared
```

```
## [1] 0.8972106
```

As we add predictors `\(R^2\)` always increases. When the predictors explain no variance,
then `\(R^2 = 0\)`. When they explain all variance, then `\(R^2 = 1\)`.

### RSE

- In simple linear regression we learned: `\(\text{RSE} = \sqrt{RSS/(n-2)}\)`
- In multiple linear regression: `\(\text{RSE} = \sqrt{RSS/(n-p-1)}\)`

Let's see what the RSE of our models look like:


```r
summary(lm(sales ~ TV , data=ads))$sigma
```

```
## [1] 3.258656
```

```r
summary(lm(sales ~ TV + radio, data=ads))$sigma
```

```
## [1] 1.681361
```

```r
summary(lm(sales ~ TV + radio + newspaper, data=ads))$sigma
```

```
## [1] 1.68551
```

- The model that includes `newspaper` has a higher RSE than the model with only
`TV` and `radio`
- This is because RSE depends on `\(p\)`

### Visual inspection

- Plotting the data can reveal problems that are not evident from metrics

The model that includes `TV` and `radio` has some issues. Let's see if we can discover
them by visualization. 

Let's start with my favorite quality assessment plot: the quantiles plot:


```r
fit = lm(sales ~ TV + radio, data=ads)
plot(fit, which=2)
```

![](session-regression-II-files/figures/unnamed-chunk-19-1.png)&lt;!-- --&gt;

This is not what I would expect normally distributed residuals to look like!

Let's see if we can get a better idea of where things are going wrong. 
Let's try and plot `\(\hat{Y}\)` (fitted values) versus the residuals:


```r
# NB: predict()  
plot(fit, which=1)
```

![](session-regression-II-files/figures/unnamed-chunk-20-1.png)&lt;!-- --&gt;

We see a dip in residuals and an increase in variance towards the middle of the range
of fitted values. It looks like our model is not adequate. 

In fact, this model fails to capture a synergy between TV and radio advertizing:


```r
# Here we rely on resid() returning the residuals in the same order as the ads data.frame
plot_dat = data.frame(TV=ads$TV, radio=ads$radio, residual=resid(fit))

library(ggplot2)
ggplot(aes(x=TV, y=radio, color=residual), data=plot_dat) + geom_point() +
  scale_color_gradient2()
```

![](session-regression-II-files/figures/unnamed-chunk-21-1.png)&lt;!-- --&gt;

- The model overestimates sales generated from investment in a single ads platform 
  (top left and bottom right)
- The model underestimates sales generated from investment in both add platforms
  (top right and bottom left)
  
We can model this synergy as an "interaction term". Unfortunately, interaction terms
are beyond the scope of this session. 
See [further reading](#further-reading) for more on interaction terms.

## What is the model's prediction accuracy?

- Previously: we can make predictions from our model using the `predict()` function.


```r
# making a prediction on a new data point
predict(fit, newdata=data.frame(TV=100, radio=30))
```

```
##        1 
## 13.13641
```

There are three sources of error when making predictions from a linear model

1. *reducible error*: A result of the difference between the estimates 
   `$$\hat{Y} = \hat\beta_0 + \hat\beta_1 X_1 + ... + \hat\beta_p X_p$$`
   and the *true population regression plane*
   `$$f(x) = \beta_0 + \beta_1 X_1 + ... + \beta_p X_p$$`
   We use *confidence intervals* to estimate this error.
2. *model bias*: When our model differs from the true model 
   (see for example the previous section)
3. *irreducible error*: The random noise that is part of our system, `\(\epsilon\)`. We can
   use *prediction intervals* to estimate this error.

If we assume that we have the correct model, then we can ask two kinds of questions:

1. How far is `\(\hat{Y}\)` from `\(f(x)\)`? 
   - We use *confidence intervals* to talk about how 
     our estimate of average sales will differ from the true average of sales
2. How far is any one prediction from its true value?
   - For this, we use *prediction intervals*

Prediction intervals are always larger than confidence intervals because prediction
intervals quantify both the reducible and irreducible error.

Let's try and calculate the confidence and prediction intervals around `\(\hat{Y}\)` of our
(dubious) model fit:


```r
preds = as.data.frame(predict(fit, interval="confidence"))
head(preds)
```

```
##        fit      lwr      upr
## 1 20.55546 20.16278 20.94815
## 2 12.34536 11.89093 12.79979
## 3 12.33702 11.76734 12.90670
## 4 17.61712 17.24763 17.98660
## 5 13.22391 12.90049 13.54733
## 6 12.51208 11.89485 13.12932
```

```r
preds2 = as.data.frame(predict(fit, interval="prediction"))
```

```
## Warning in predict.lm(fit, interval = "prediction"): predictions on current data refer to _future_ responses
```

```r
head(preds2)
```

```
##        fit       lwr      upr
## 1 20.55546 17.216516 23.89441
## 2 12.34536  8.998591 15.69213
## 3 12.33702  8.972659 15.70138
## 4 17.61712 14.280817 20.95341
## 5 13.22391  9.892396 16.55542
## 6 12.51208  9.139348 15.88482
```

```r
preds$lwr_pred = preds2$lwr
preds$upr_pred = preds2$upr

preds = preds[order(preds$fit),]
preds$index = 1:nrow(preds)
head(preds)
```

```
##          fit      lwr      upr  lwr_pred upr_pred index
## 109 3.595686 3.041903 4.149468 0.2339824 6.957389     1
## 9   3.709379 3.163756 4.255002 0.3490103 7.069748     2
## 193 4.478859 3.966817 4.990901 1.1237791 7.833939     3
## 77  4.480148 3.962410 4.997886 1.1241941 7.836102     4
## 92  4.511679 3.994733 5.028625 1.1558471 7.867511     5
## 156 5.289428 4.804825 5.774031 1.9384257 8.640430     6
```


```r
plot(preds$fit, type='l')
lines(preds$index, preds$upr, col='red')
lines(preds$index, preds$lwr, col='red')
lines(preds$index, preds$upr_pred, col='blue')
lines(preds$index, preds$lwr_pred, col='blue')
```

![](session-regression-II-files/figures/unnamed-chunk-24-1.png)&lt;!-- --&gt;

We can see that the prediction intervals are larger than the confidence intervals. 
However, neither the confidence intervals nor the prediction intervals are valid here.

**Caveats**:

  - Our model does not fit the data well, and so we are also dealing with model bias.
    The confidence interval calculations assume a good model fit, which is clearly not 
    the case here.
  - Calculating prediction intervals on the data we used to create the model underestimates
    the prediction error on new data. Generally, we are interested in prediction intervals
    for new data. For that we need to calculate prediction intervals on a separate 
    (or held out) data set.

--- 

# Further reading

.pull-left[This lecture closely followed section 3.2 in 
*An Introduction to Statistical Learning, with applications in R*]

.pull-right[![An Introduction to Statistical Learning](./assets/qrcode.int_stat_learn.png)]

## But there's more!

- Section 3.3 is worth a read before you start 
fitting linear models to your data. That section discusses the following topics:

  - Qualitative predictors 
  - Interaction terms
  - Non-linear transformation of the predictors 
  - Potential problems: non-linearity, collinearity, outliers, heteroskedasticity
  - Logistic regression

## Libraries

- ggplot2
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
