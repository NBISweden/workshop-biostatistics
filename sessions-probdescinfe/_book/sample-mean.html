<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Sample mean | Introduction to Biostatistics and Machine Learning</title>
  <meta name="description" content="This is the course literature for the NBIS course Introduction to Biostatistics and Machine Learning." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Sample mean | Introduction to Biostatistics and Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the course literature for the NBIS course Introduction to Biostatistics and Machine Learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Sample mean | Introduction to Biostatistics and Machine Learning" />
  
  <meta name="twitter:description" content="This is the course literature for the NBIS course Introduction to Biostatistics and Machine Learning." />
  

<meta name="author" content="NBIS" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistical-inference.html"/>
<link rel="next" href="multiple-testing.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>1</b> Probability theory</a><ul>
<li class="chapter" data-level="1.1" data-path="probability-theory.html"><a href="probability-theory.html#random-variables"><i class="fa fa-check"></i><b>1.1</b> Random variables</a><ul>
<li class="chapter" data-level="1.1.1" data-path="probability-theory.html"><a href="probability-theory.html#discrete-random-variables"><i class="fa fa-check"></i><b>1.1.1</b> Discrete random variables</a></li>
<li class="chapter" data-level="1.1.2" data-path="probability-theory.html"><a href="probability-theory.html#continuous-random-variable"><i class="fa fa-check"></i><b>1.1.2</b> Continuous random variable</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probability-theory.html"><a href="probability-theory.html#simulate-distributions"><i class="fa fa-check"></i><b>1.2</b> Simulate distributions</a></li>
<li class="chapter" data-level="1.3" data-path="probability-theory.html"><a href="probability-theory.html#parametric-discrete-distributions"><i class="fa fa-check"></i><b>1.3</b> Parametric discrete distributions</a></li>
<li class="chapter" data-level="1.4" data-path="probability-theory.html"><a href="probability-theory.html#discrete-distributions"><i class="fa fa-check"></i><b>1.4</b> Discrete distributions</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probability-theory.html"><a href="probability-theory.html#bernoulli-trial"><i class="fa fa-check"></i><b>1.4.1</b> Bernoulli trial</a></li>
<li class="chapter" data-level="1.4.2" data-path="probability-theory.html"><a href="probability-theory.html#binomial-distribution"><i class="fa fa-check"></i><b>1.4.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="1.4.3" data-path="probability-theory.html"><a href="probability-theory.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>1.4.3</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="1.4.4" data-path="probability-theory.html"><a href="probability-theory.html#poisson-distribution"><i class="fa fa-check"></i><b>1.4.4</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>1.5</b> Conditional probability</a><ul>
<li class="chapter" data-level="1.5.1" data-path="probability-theory.html"><a href="probability-theory.html#diagnostic-tests---passar-bättre-i-samband-med-klassificering"><i class="fa fa-check"></i><b>1.5.1</b> Diagnostic tests - passar bättre i samband med klassificering?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="desc.html"><a href="desc.html"><i class="fa fa-check"></i><b>2</b> Descriptive statistics and distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="desc.html"><a href="desc.html#data-types"><i class="fa fa-check"></i><b>2.1</b> Data types</a></li>
<li class="chapter" data-level="2.2" data-path="desc.html"><a href="desc.html#measures-of-location"><i class="fa fa-check"></i><b>2.2</b> Measures of location</a><ul>
<li class="chapter" data-level="2.2.1" data-path="desc.html"><a href="desc.html#expected-value"><i class="fa fa-check"></i><b>2.2.1</b> Expected value</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="desc.html"><a href="desc.html#measures-of-spread"><i class="fa fa-check"></i><b>2.3</b> Measures of spread</a><ul>
<li class="chapter" data-level="2.3.1" data-path="desc.html"><a href="desc.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>2.3.1</b> Variance and standard deviation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="parametric-continuous-distributions.html"><a href="parametric-continuous-distributions.html"><i class="fa fa-check"></i><b>3</b> Parametric continuous distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="parametric-continuous-distributions.html"><a href="parametric-continuous-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>3.1</b> Normal distribution</a></li>
<li class="chapter" data-level="3.2" data-path="parametric-continuous-distributions.html"><a href="parametric-continuous-distributions.html#central-limit-theorem"><i class="fa fa-check"></i><b>3.2</b> Central limit theorem</a></li>
<li class="chapter" data-level="3.3" data-path="parametric-continuous-distributions.html"><a href="parametric-continuous-distributions.html#chi2-distribution"><i class="fa fa-check"></i><b>3.3</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="3.4" data-path="parametric-continuous-distributions.html"><a href="parametric-continuous-distributions.html#f-distribution"><i class="fa fa-check"></i><b>3.4</b> F-distribution</a></li>
<li class="chapter" data-level="3.5" data-path="parametric-continuous-distributions.html"><a href="parametric-continuous-distributions.html#t-distribution"><i class="fa fa-check"></i><b>3.5</b> t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Statistical Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="statistical-inference.html"><a href="statistical-inference.html#random-sample"><i class="fa fa-check"></i><b>4.1</b> Random sample</a><ul>
<li class="chapter" data-level="4.1.1" data-path="statistical-inference.html"><a href="statistical-inference.html#the-urn-model-to-perform-simple-random-sampling"><i class="fa fa-check"></i><b>4.1.1</b> The urn model to perform simple random sampling</a></li>
<li class="chapter" data-level="4.1.2" data-path="statistical-inference.html"><a href="statistical-inference.html#sample-properties"><i class="fa fa-check"></i><b>4.1.2</b> Sample properties</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sample-mean.html"><a href="sample-mean.html"><i class="fa fa-check"></i><b>5</b> Sample mean</a><ul>
<li class="chapter" data-level="5.1" data-path="sample-mean.html"><a href="sample-mean.html#expected-value-and-variance"><i class="fa fa-check"></i><b>5.1</b> Expected value and variance</a></li>
<li class="chapter" data-level="5.2" data-path="sample-mean.html"><a href="sample-mean.html#hypothesis-test"><i class="fa fa-check"></i><b>5.2</b> Hypothesis test</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sample-mean.html"><a href="sample-mean.html#the-null-and-alternative-hypothesis"><i class="fa fa-check"></i><b>5.2.1</b> The null and alternative hypothesis</a></li>
<li class="chapter" data-level="5.2.2" data-path="sample-mean.html"><a href="sample-mean.html#to-perform-a-hypothesis-test"><i class="fa fa-check"></i><b>5.2.2</b> To perform a hypothesis test</a></li>
<li class="chapter" data-level="5.2.3" data-path="sample-mean.html"><a href="sample-mean.html#significance-level-and-error-types"><i class="fa fa-check"></i><b>5.2.3</b> Significance level and error types</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sample-mean.html"><a href="sample-mean.html#interval-estimate"><i class="fa fa-check"></i><b>5.3</b> Interval estimate</a><ul>
<li class="chapter" data-level="5.3.1" data-path="sample-mean.html"><a href="sample-mean.html#bootstrap-interval"><i class="fa fa-check"></i><b>5.3.1</b> Bootstrap interval</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="sample-mean.html"><a href="sample-mean.html#parametric-hypothesis-tests"><i class="fa fa-check"></i><b>5.4</b> Parametric hypothesis tests</a></li>
<li class="chapter" data-level="5.5" data-path="sample-mean.html"><a href="sample-mean.html#parametric-distributions"><i class="fa fa-check"></i><b>5.5</b> Parametric distributions</a><ul>
<li class="chapter" data-level="5.5.1" data-path="sample-mean.html"><a href="sample-mean.html#standard-error"><i class="fa fa-check"></i><b>5.5.1</b> Standard error</a></li>
<li class="chapter" data-level="5.5.2" data-path="sample-mean.html"><a href="sample-mean.html#one-sample-proportions"><i class="fa fa-check"></i><b>5.5.2</b> One sample, proportions</a></li>
<li class="chapter" data-level="5.5.3" data-path="sample-mean.html"><a href="sample-mean.html#one-sample-mean"><i class="fa fa-check"></i><b>5.5.3</b> One sample, mean</a></li>
<li class="chapter" data-level="5.5.4" data-path="sample-mean.html"><a href="sample-mean.html#two-samples-known-sigma_1-and-sigma_2"><i class="fa fa-check"></i><b>5.5.4</b> Two samples, known <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span></a></li>
<li class="chapter" data-level="5.5.5" data-path="sample-mean.html"><a href="sample-mean.html#unknown-standard-deviations"><i class="fa fa-check"></i><b>5.5.5</b> Unknown standard deviations</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="sample-mean.html"><a href="sample-mean.html#confidence-interval"><i class="fa fa-check"></i><b>5.6</b> Confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>6</b> Multiple testing</a><ul>
<li class="chapter" data-level="6.1" data-path="multiple-testing.html"><a href="multiple-testing.html#error-types"><i class="fa fa-check"></i><b>6.1</b> Error types</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bonferroni-correction.html"><a href="bonferroni-correction.html"><i class="fa fa-check"></i><b>7</b> Bonferroni correction</a></li>
<li class="chapter" data-level="8" data-path="benjamini-hochbegs-fdr.html"><a href="benjamini-hochbegs-fdr.html"><i class="fa fa-check"></i><b>8</b> Benjamini-Hochbegs FDR</a></li>
<li class="chapter" data-level="9" data-path="adjusted-p-values.html"><a href="adjusted-p-values.html"><i class="fa fa-check"></i><b>9</b> ‘Adjusted’ p-values</a><ul>
<li class="chapter" data-level="9.1" data-path="adjusted-p-values.html"><a href="adjusted-p-values.html#example-10000-independent-tests-e.g.-genes"><i class="fa fa-check"></i><b>9.1</b> Example, 10000 independent tests (e.g. genes)</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Biostatistics and Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sample-mean" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Sample mean</h1>
<div id="expected-value-and-variance" class="section level2">
<h2><span class="header-section-number">5.1</span> Expected value and variance</h2>
<p>The mean of <span class="math inline">\(n\)</span> independent identically distributed random variables with <span class="math inline">\(E[X_i] = E[X] = \mu\)</span> and <span class="math inline">\(var(X_i) = var(X) = \sigma^2\)</span></p>
<p><span class="math display">\[\bar X = \frac{1}{n}\sum_{i=1}^n X_i\]</span></p>
<p>is also a random variable.</p>
<p><span class="math display">\[E[\bar X] = \mu\]</span></p>
<p><span class="math display">\[SE = \frac{\sigma}{\sqrt{n}}\]</span></p>
<p>If <span class="math inline">\(X_i \sim N(\mu, \sigma)\)</span> then <span class="math inline">\(\bar X \sim N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)\)</span>.</p>
<div id="sample-mean-1" class="section level4">
<h4><span class="header-section-number">5.1.0.1</span> Sample mean</h4>
<p>The sample mean is denoted <span class="math inline">\(m = \bar x\)</span>. For a sample of size <span class="math inline">\(n\)</span> the sample mean is:</p>
<p><span class="math display">\[m = \bar x = \frac{1}{n}\displaystyle\sum_{i=1}^n x_i\]</span></p>
<p>When we only have a sample of size <span class="math inline">\(n\)</span>, the sample mean <span class="math inline">\(m\)</span> is our best estimate of the population mean. It is possible to show that the sample mean is an unbiased estimate of the sample mean, i.e. the average (over many size <span class="math inline">\(n\)</span> samples) of the sample mean is <span class="math inline">\(\mu\)</span>.</p>
<p><span class="math display">\[E[\bar X] = \frac{1}{n} n E[X] = E[X] = \mu\]</span></p>
</div>
<div id="sample-variance-and-standard-deviation" class="section level4">
<h4><span class="header-section-number">5.1.0.2</span> Sample variance and standard deviation</h4>
<p>The sample variance is computed as</p>
<p><span class="math display">\[s^2 = \frac{1}{n-1} \sum_{i=1}^n (x-m)^2\]</span>
The sample variance is an unbiased estimate of the population variance.</p>
<p><span class="math display">\[E[s^2] = \sigma^2\]</span>
The sample standard deviation, <span class="math inline">\(s\)</span>, is computed as the square root of the sample variance.</p>
</div>
</div>
<div id="hypothesis-test" class="section level2">
<h2><span class="header-section-number">5.2</span> Hypothesis test</h2>
<p>In a hypothesis test a hypothesis is evaluated based on a random sample.</p>
<p>The hypotheses that are tested are assumptions about properties of the population, such as proportion, mean, mean difference etc.</p>
<div id="the-null-and-alternative-hypothesis" class="section level3">
<h3><span class="header-section-number">5.2.1</span> The null and alternative hypothesis</h3>
<p>There are two hypotheses involved in a hypothesis test, the null hypothesis, <span class="math inline">\(H_0\)</span>, and the alternative hypothesis, <span class="math inline">\(H_1\)</span>.</p>
<p>The null hypothesis is in general neutral, “no change”, “no difference between groups”, “no association”. In general we want to show that <span class="math inline">\(H_0\)</span> is false.</p>
<p>The alternative hypothesis expresses what the researcher is interested in “the treatment has an effect”, “there is a difference between groups”, “there is an association”. The alternative hypothesis can also be directional “the treatment has a positive effect”.</p>
</div>
<div id="to-perform-a-hypothesis-test" class="section level3">
<h3><span class="header-section-number">5.2.2</span> To perform a hypothesis test</h3>
<ol style="list-style-type: decimal">
<li>Define null <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span></li>
<li>Select appropriate test statistic, <span class="math inline">\(T\)</span>, and compute the observed value, <span class="math inline">\(t_{obs}\)</span></li>
<li>Assume that the <span class="math inline">\(H_0\)</span> is true and compute the sampling distribution of <span class="math inline">\(T\)</span>.</li>
<li>Compare the observed value, <span class="math inline">\(t_{obs}\)</span>, with the computed sampling distribution under <span class="math inline">\(H_0\)</span> and compute a p-value. The p-value is the probability of observing a value at least as extreme as the observed value, if <span class="math inline">\(H_0\)</span> is true.</li>
<li>Based on the p-value either accept or reject <span class="math inline">\(H_0\)</span>.</li>
</ol>

<div class="definition">
<p><span id="def:samplingdistribution" class="definition"><strong>Definition 5.1  </strong></span><strong>Sampling distribution</strong></p>
A sampling distribution is the distribution of a statistic of a large number of samples drawn from a specific population.
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-14" class="definition"><strong>Definition 5.2  </strong></span><strong>p-value</strong></p>
The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.
</div>

</div>
<div id="significance-level-and-error-types" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Significance level and error types</h3>
<table>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
H0 is true
</td>
<td style="text-align:left;">
H0 is false
</td>
</tr>
<tr>
<td style="text-align:left;">
Accept H0
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Type II error, miss
</td>
</tr>
<tr>
<td style="text-align:left;">
Reject H0
</td>
<td style="text-align:left;">
Type I error, false alarm
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p>The significance level, <span class="math inline">\(\alpha\)</span> = P(false alarm) = P(Reject H0|H0 is true)</p>
<div id="simulation-example" class="section level4">
<h4><span class="header-section-number">5.2.3.1</span> Simulation example</h4>
<p>Let’s assume we know that the proportion of pollen allergy in Sweden is <span class="math inline">\(0.3\)</span>. We suspect that the number of pollen allergic has increased in Uppsala in the last couple of years and want to investigate this.</p>
<p>Observe 100 people from Uppsala, 42 of these were allergic to pollen. Is there a reason to believe that the proportion of pollen allergic in Uppsala <span class="math inline">\(\pi &gt; 0.3\)</span>?
```</p>
<div id="null-and-alternative-hypotheses" class="section level5 unnumbered">
<h5>Null and alternative hypotheses</h5>
<p><span class="math inline">\(H_0:\)</span> The proportion of pollen allergy in Uppsala is the same as in Sweden as a whole.</p>
<p><span class="math inline">\(H_1:\)</span> The proportion of pollen allergy in Uppsala is not the same as in Sweden as a whole.</p>
<p>or expressed differently;</p>
<p><span class="math display">\[H_0:\, \pi=\pi_0\]</span></p>
<p><span class="math display">\[H_1:\, \pi&gt;\pi_0\]</span>
where <span class="math inline">\(\pi\)</span> is the unknown proportion of pollen allergy in the Uppsala population that. <span class="math inline">\(\pi_0 = 0.3\)</span> is the proportion of pollen allergy in Sweden.</p>
</div>
<div id="test-statistic" class="section level5 unnumbered">
<h5>Test statistic</h5>
<p>Here we are interested in the proportion of pollen allergy in our Uppsala sample. An appropriate test statistic could be the number of pollen allergic in a sample of size <span class="math inline">\(n=100\)</span>, <span class="math inline">\(X\)</span>. As an alternative we can use the proportion of pollen allergic in a sample of size <span class="math inline">\(n\)</span>,</p>
<p><span class="math display">\[P = \frac{X}{n}\]</span></p>
<p>Let’s use <span class="math inline">\(P\)</span> as our test statistic and compute the observed value, <span class="math inline">\(p_{obs}\)</span>. In our sample of 100 people from Uppsala the proportion allergic to pollen is <span class="math inline">\(p=42/100=0.42\)</span>.</p>
</div>
<div id="null-distribution" class="section level5 unnumbered">
<h5>Null distribution</h5>
<p>The sampling distribution of <span class="math inline">\(P\)</span> under <span class="math inline">\(H_0\)</span> (i.e. when the null hypothesis is true) is what we call the null distribution.</p>
<p>Our <span class="math inline">\(H_0\)</span> state that <span class="math inline">\(\pi=0.3\)</span>. We can model this using an urn model as follows;</p>
<div class="figure" style="text-align: center"><span id="fig:pollenurn"></span>
<img src="figures/pollenurn.png" alt="An urn model of the null hypothesis $\pi=0.3$. The black balls represent allergic and the white balls non-allergic." width="20%" />
<p class="caption">
Figure 5.1: An urn model of the null hypothesis <span class="math inline">\(\pi=0.3\)</span>. The black balls represent allergic and the white balls non-allergic.
</p>
</div>
<p>Using this model, we can simulate taking a sample of 100 many times.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1"><span class="co">## Urn</span></a>
<a class="sourceLine" id="cb19-2" title="2"><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>##  [1] 0 0 0 0 0 0 0 1 1 1</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1"><span class="co">## Sample 100 times with replacement</span></a>
<a class="sourceLine" id="cb21-2" title="2"><span class="kw">sample</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>)), <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##   [1] 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1
##  [38] 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1
##  [75] 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1"><span class="co">## Compute proportion of samples that are allergic (1)</span></a>
<a class="sourceLine" id="cb23-2" title="2"><span class="kw">sum</span>(<span class="kw">sample</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>)), <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>))<span class="op">/</span><span class="dv">100</span></a></code></pre></div>
<pre><code>## [1] 0.36</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1"><span class="co">## Draw samples of size 100 and compute proporion allergic 100000 times</span></a>
<a class="sourceLine" id="cb25-2" title="2">p &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100000</span>, <span class="kw">mean</span>(<span class="kw">sample</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>)), <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)))</a></code></pre></div>
<p>Finally plot the distribution</p>
<div class="figure" style="text-align: center"><span id="fig:pollensampledistr"></span>
<img src="biostatbook_files/figure-html/pollensampledistr-1.png" alt="The sampling distribution." width="45%" />
<p class="caption">
Figure 5.2: The sampling distribution.
</p>
</div>
</div>
<div id="compute-p-value" class="section level5 unnumbered">
<h5>Compute p-value</h5>
<p>Compare the observed value, <span class="math inline">\(p_{obs} = 0.42\)</span> to the null distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="biostatbook_files/figure-html/unnamed-chunk-17-1.png" alt="The sampling istribution. The observed value is marked by a red vertical line." width="50%" />
<p class="caption">
Figure 5.3: The sampling istribution. The observed value is marked by a red vertical line.
</p>
</div>
<p>The p-value is the probability of getting the observed value or higher, if the null hypothesis is true.</p>
<p>Use the null distribution to calculate the p-value, <span class="math inline">\(P(P \geq 0.42|H_0)\)</span>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" title="1"><span class="co">## How many times </span></a>
<a class="sourceLine" id="cb26-2" title="2"><span class="kw">sum</span>(p <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.42</span>)</a></code></pre></div>
<pre><code>## [1] 715</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" title="1"><span class="co">## p-value</span></a>
<a class="sourceLine" id="cb28-2" title="2"><span class="kw">sum</span>(p <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.42</span>)<span class="op">/</span><span class="kw">length</span>(p)</a></code></pre></div>
<pre><code>## [1] 0.0072</code></pre>
<p>p = <span class="math inline">\(P(P \geq 0.42|H_0)\)</span> = 0.00715</p>
</div>
<div id="accept-or-reject-h_0" class="section level5 unnumbered">
<h5>Accept or reject <span class="math inline">\(H_0\)</span>?</h5>
</div>
</div>
<div id="example-permutation-test" class="section level4">
<h4><span class="header-section-number">5.2.3.2</span> Example, permutation test</h4>
<div id="do-high-fat-diet-lead-to-increased-body-weight" class="section level5 unnumbered">
<h5>Do high fat diet lead to increased body weight?</h5>
<p>Study setup:</p>
<ol style="list-style-type: decimal">
<li>Order 24 female mice from a lab.</li>
<li>Randomly assign 12 of the 24 mice to receive high-fat diet, the
remaining 12 are controls (ordinary diet).</li>
<li>Measure body weight after one week.</li>
</ol>
</div>
<div id="null-and-alternative-hypotheses-1" class="section level5 unnumbered">
<h5>Null and alternative hypotheses</h5>
<p><span class="math display">\[
\begin{aligned}
H_0: \mu_2 = \mu_1 \iff \mu_2 - \mu_1 = 0\\
H_1: \mu_2&gt;\mu_1 \iff \mu_2-\mu_1 &gt; 0
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mu_2\)</span> is the (unknown) mean body weight of the high-fat mouse population and <span class="math inline">\(\mu_1\)</span> is the mean body-weight of the control mouse population.</p>
<p>Studied population: Female mice that can be ordered from a lab.</p>
</div>
<div id="test-statistic-1" class="section level5 unnumbered">
<h5>Test statistic</h5>
<p>Here we are interested in the mean difference between high-fat and control mice.</p>
<p>Mean weight of 12 (randomly selected) mice on ordinary diet, <span class="math inline">\(\bar X_1\)</span>. <span class="math inline">\(E[\bar X_1] = E[X_1] = \mu_1\)</span></p>
<p>Mean weight of 12 (randomly selected) mice on high-fat diet, <span class="math inline">\(\bar X_2\)</span>. <span class="math inline">\(E[\bar X_2] = E[X_2] = \mu_2\)</span></p>
<p>The mean difference is also a random variable: <span class="math inline">\(D = \bar X_2 - \bar X_1\)</span></p>
<p>The observed values are summarized below;</p>
<table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
high-fat
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
39
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
32
</td>
</tr>
<tr>
<td style="text-align:left;">
ordinary
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
24
</td>
</tr>
</tbody>
</table>
<p>Mean weight of control mice (ordinary diet): <span class="math inline">\(\bar x_1 = 25.73\)</span></p>
<p>Mean weight of mice on high-fat diet: <span class="math inline">\(\bar x_2 = 28.21\)</span></p>
<p>Difference in mean weights: <span class="math inline">\(d_{obs} = \bar x_2 - \bar x_1 = 2.49\)</span></p>
</div>
<div id="null-distribution-1" class="section level5 unnumbered">
<h5>Null distribution</h5>
<p>If high-fat diet has no effect, i.e. if <span class="math inline">\(H_0\)</span> was true, the result would be as if all mice were given the same diet. What can we expect if all mice are fed with the same type of food?</p>
<p>This can be accomplished using permutation</p>
<p>The 24 mice were initially from the same population, depending on how the mice are randomly assigned to high-fat and normal group, the mean weights would differ, even if the two groups were treated the same.</p>
<p>Assume <span class="math inline">\(H_0\)</span> is true, i.e. assume all mice are equivalent and</p>
<ol style="list-style-type: decimal">
<li>Randomly reassign 12 of the 24 mice to ‘high-fat’ and the remaining 12 to ‘control’.</li>
<li>Compute difference in mean weights</li>
</ol>
<p>If we repeat 1-2 many times we get the sampling distribution when <span class="math inline">\(H_0\)</span> is true, the so called null distribution, of difference in mean weights.</p>
<p><img src="biostatbook_files/figure-html/permtest-1.png" width="50%" /></p>
</div>
<div id="compute-p-value-1" class="section level5 unnumbered">
<h5>Compute p-value</h5>
<p>What is the probability to get an at least as extreme mean difference as our observed value, <span class="math inline">\(d_{obs}\)</span>, if <span class="math inline">\(H_0\)</span> was true?</p>
<p><span class="math display">\[P(\bar X_2 - \bar X_2 \geq d_{obs} | H_0) = \]</span>0.126</p>
<p>Conclusion?</p>
</div>
</div>
</div>
</div>
<div id="interval-estimate" class="section level2">
<h2><span class="header-section-number">5.3</span> Interval estimate</h2>
<ul>
<li>How large proportion of the Uppsala population is allergic to pollen?</li>
<li>Investigate this by randomly selecting 100 persons. It is important to actually sample randomly, ideally every individual should have the same probability of being sampled.</li>
<li>Observe that 42 of the 100 has a pollen allergy. Hence, the observed sample proportion is <span class="math inline">\(p=0.42\)</span>.</li>
<li>What does this say about the population proportion <span class="math inline">\(\pi\)</span>?</li>
<li>Our best guess would be <span class="math inline">\(\pi \approx p = 0.42\)</span>, but how accurate is this?</li>
<li>If the experiment is repeated, we get a slightly different result.</li>
</ul>
<div id="bootstrap-interval" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Bootstrap interval</h3>
<p>Using bootstrap we can sample with replacement from our sample to estimate the uncertainty.</p>
<p>Put the entire sample in an urn!</p>
<div class="figure" style="text-align: center"><span id="fig:pollenurn42"></span>
<img src="figures/pollenurn42.png" alt="An urn model with 42 allergy (black) and 58 non-allergy (white). The black balls represent allergic and the white balls non-allergic." width="20%" />
<p class="caption">
Figure 5.4: An urn model with 42 allergy (black) and 58 non-allergy (white). The black balls represent allergic and the white balls non-allergic.
</p>
</div>
<p>Sample from the urn with replacement to compute the bootstrap distribution.</p>
<p><img src="biostatbook_files/figure-html/CIboot-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Using the bootstrap distribution the uncertainty of our estimate of <span class="math inline">\(\pi\)</span> can be estimated.</p>
<p>The 95% bootstrap interval is [0.24, 0.42].</p>
<p>The bootstrap is very useful if you do not know the distribution of our sampled propery. But in our example we actually do.</p>
</div>
</div>
<div id="parametric-hypothesis-tests" class="section level2">
<h2><span class="header-section-number">5.4</span> Parametric hypothesis tests</h2>
</div>
<div id="parametric-distributions" class="section level2">
<h2><span class="header-section-number">5.5</span> Parametric distributions</h2>
<div id="standard-error" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Standard error</h3>
<p>Remember the sampling distribution</p>
<p><img src="biostatbook_files/figure-html/unnamed-chunk-21-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>The standard deviation of the sampling distribution is called the standard error, SE.</p>
<div id="back-to-the-pollen-example" class="section level5">
<h5><span class="header-section-number">5.5.1.0.1</span> Back to the pollen example</h5>
<p>Denote the outcome of one trial (selecting one person) <span class="math inline">\(X\)</span>. (1=success, 0=failure)</p>
<p>If we randomly select 100 persons, this is equivalent to 100 independent identical Bernouilli trials.</p>
<p>The fraction of sucesses in a sample of size n is another random variable;</p>
<p><span class="math display">\[P = \frac{1}{n} \sum_{i=1}^n X_i\]</span></p>
<p>Central limit theorem gives that <span class="math inline">\(P\)</span> is approximately normally distributed.</p>
<p><span class="math display">\[P \sim N\left(\pi, \sqrt{\frac{\pi(1-\pi)}{n}}\right)\]</span></p>
<p>The standard deviation of the sampling distribution is called the standard error. For proportions the standard error is</p>
<p><span class="math display">\[SE=\sqrt{\frac{\pi(1-\pi)}{n}}\]</span></p>
<p>The formula for the standard error contains our unknown parameter <span class="math inline">\(\pi\)</span>. No problem, let’s replace <span class="math inline">\(\pi\)</span> with our best estimate of <span class="math inline">\(\pi\)</span>: <span class="math inline">\(p\)</span>!</p>
<p><span class="math display">\[
SE = \sqrt{\frac{p(1-p)}{n}}
\]</span></p>
</div>
</div>
<div id="one-sample-proportions" class="section level3">
<h3><span class="header-section-number">5.5.2</span> One sample, proportions</h3>
<p>If <span class="math inline">\(H_0\)</span> is true <span class="math inline">\(\pi=\pi_0\)</span> and</p>
<p><span class="math display">\[P \sim N\left(\pi_0, \sqrt{\frac{\pi_0(1-\pi_0)}{n}}\right)\]</span>
Test statistic <span class="math display">\[Z = \frac{P-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}\]</span></p>
<p>Replace <span class="math inline">\(P\)</span> with our observed value <span class="math inline">\(p=0.42\)</span> and compute our observed
<span class="math display">\[Z_{obs} = \frac{0.42-0.3}{\sqrt{\frac{0.3(1-0.3)}{100}}} = 2.62\]</span></p>
<p>The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.</p>
<p><span class="math display">\[p = P(P&gt;\pi_0) = P(Z&gt;Z_{obs}) = P(Z&gt;2.62) = [table]\]</span></p>
<p>Conclusion?</p>
</div>
<div id="one-sample-mean" class="section level3">
<h3><span class="header-section-number">5.5.3</span> One sample, mean</h3>
<p>If <span class="math display">\[X \sim N(\mu, \sigma)\]</span> then <span class="math display">\[\bar X \sim N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)\]</span></p>
<p>If <span class="math inline">\(\sigma\)</span> is known</p>
<p><span class="math display">\[Z = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)\]</span></p>
<p>For small <span class="math inline">\(n\)</span> and unknown <span class="math inline">\(\sigma\)</span></p>
<p><span class="math display">\[t = \frac{\bar X - \mu}{\frac{s}{\sqrt{n}}},\]</span>
where <span class="math inline">\(t\)</span> is t-distributed with <span class="math inline">\(df=n-1\)</span> degrees of freedom.</p>
<p>The hemoglobin value (Hb) in women is on average 140 g/L. You observe the following Hb values in a set of five men: 154, 140, 147, 162, 172. Assume that Hb is normally distributed. Is there a reason to believe that the mean Hb value in men differ from that in women?</p>
</div>
<div id="two-samples-known-sigma_1-and-sigma_2" class="section level3">
<h3><span class="header-section-number">5.5.4</span> Two samples, known <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span></h3>
<p><span class="math display">\[H_0: \mu_2 = \mu_1\]</span>
<span class="math display">\[H_1: \mu_2&gt;\mu_1\]</span></p>
<p>Let’s assume that both mouse body weights in control and treatment groups are independent and normally distributed, with unknown mean, but known standard deviations, <span class="math inline">\(\sigma_1=3.4\)</span> and <span class="math inline">\(\sigma_2=5.1\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
X_1 \sim N(\mu_1, \sigma_1) \\
X_2 \sim N(\mu_2, \sigma_2)
\end{aligned}
\]</span></p>
<p>If follows that the sample means are</p>
<p><span class="math display">\[
\begin{aligned}
\bar X_1 \sim N(\mu_1, \sigma_1/\sqrt{n_1}) \\
\bar X_2 \sim N(\mu_2, \sigma_2/\sqrt{n_2})
\end{aligned}
\]</span></p>
<p>The mean difference <span class="math inline">\(D = \bar X_2 - \bar X_1\)</span> is thus also normally distributed:</p>
<p><span class="math display">\[D = \bar X_2 - \bar X_1 = N\left(\mu_2-\mu_1, \sqrt{\frac{\sigma_2^2}{n_2} + \frac{\sigma_1^2}{n_1}}\right)\]</span></p>
<p>If <span class="math inline">\(H_0\)</span> is true: <span class="math display">\[D = \bar X_2 - \bar X_1 = N\left(0, \sqrt{\frac{\sigma_2^2}{n_2} + \frac{\sigma_1^2}{n_1}}\right)\]</span></p>
<p>The test statistic: <span class="math display">\[Z = \frac{\bar X_2 - \bar X_1 - 0}{\sqrt{\frac{\sigma_2^2}{n_2} + \frac{\sigma_1^2}{n_1}}}\]</span> is standard normal, i.e. <span class="math inline">\(Z \sim N(0,1)\)</span>.</p>
</div>
<div id="unknown-standard-deviations" class="section level3">
<h3><span class="header-section-number">5.5.5</span> Unknown standard deviations</h3>
<p>What if the population standard deviations are not known?</p>
<p>If the sample sizes are large, we can replace the known standard deviations with our sample standard deviations and according to the central limit theorem assume that</p>
<!-- $$Z = \frac{\bar X_2 - \bar X_1}{\sqrt{s_2^2/\sqrt{n_2} + s_1^2/\sqrt{n_1}}} \sim N(0,1)$$ -->
<p>and procede as before.</p>
<p>Here <span class="math inline">\(n_1=n_2=12\)</span> which is not very large.</p>
<p>For small sample sizes we can use Student’s t-test, which requires us to assume that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> both are normally distributed and have equal variances. With these assumptions we can compute the pooled variance</p>
<p><span class="math display">\[
s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}
\]</span></p>
<p>and the test statistic</p>
<p><span class="math display">\[t = \frac{\bar X_1 - \bar X_2 - 0}{\sqrt{s_p^2(\frac{1}{n_1} + \frac{1}{n_2})}}\]</span></p>
<p><span class="math inline">\(t\)</span> is t-distributed with <span class="math inline">\(n_1+n_2-2\)</span> degrees of freedom.</p>
<p>The t-test is implemented in R.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" title="1"><span class="co"># Student&#39;s t-test with pooled variances</span></a>
<a class="sourceLine" id="cb30-2" title="2"><span class="kw">t.test</span>(xHF, xN, <span class="dt">var.equal=</span><span class="ot">TRUE</span>, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<pre><code>## 
## 	Two Sample t-test
## 
## data:  xHF and xN
## t = 1, df = 22, p-value = 0.1
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  -1.1  Inf
## sample estimates:
## mean of x mean of y 
##        28        26</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1"><span class="co"># Unequal variances with Welch approximation to the degrees of freedom (the default)</span></a>
<a class="sourceLine" id="cb32-2" title="2"><span class="kw">t.test</span>(xHF, xN, <span class="dt">var.equal=</span><span class="ot">FALSE</span>, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<pre><code>## 
## 	Welch Two Sample t-test
## 
## data:  xHF and xN
## t = 1, df = 20, p-value = 0.1
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  -1.1  Inf
## sample estimates:
## mean of x mean of y 
##        28        26</code></pre>
</div>
</div>
<div id="confidence-interval" class="section level2">
<h2><span class="header-section-number">5.6</span> Confidence interval</h2>
<p>Based on what we know of the normal distribution, we can conclude that</p>
<p><span class="math display">\[Pr\left(-1.96 &lt; \frac{P-\pi}{SE}&lt;1.96\right) = 0.95\]</span>
We can rewrite this to
<span class="math display">\[Pr\left(\pi-1.96 SE &lt; P &lt; \pi + 1.96 SE\right) = 0.95\]</span>
in other words sample fraction <span class="math inline">\(p\)</span> will fall between <span class="math inline">\(\pi \pm 1.96 SE\)</span> with 95% probability.</p>
<p>The equation can also be rewritten to
<span class="math display">\[Pr\left(P-1.96 SE &lt; \pi &lt; P + 1.96 SE\right) = 0.95\]</span>
The observed confidence interval is what we get when we replace the random variable <span class="math inline">\(P\)</span> with our observed fraction, i.e. our 95% confidence interval is</p>
<p><span class="math display">\[p-1.96\sqrt{\frac{p(1-p)}{n}}) &lt; \pi &lt; p + 1.96\sqrt{\frac{p(1-p)}{n}}\]</span>
<span class="math display">\[\pi = p \pm 1.96 \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<p>A 95% confidence interval will have 95% chance to cover the true value.</p>
<p><img src="biostatbook_files/figure-html/CI-1.png" width="4200" /></p>
<div id="pollen-allergy-ci" class="section level5 unnumbered">
<h5>Pollen allergy, CI</h5>
<p>Back to our example. <span class="math inline">\(p=0.33\)</span> and <span class="math inline">\(SE=\sqrt{\frac{p(1-p)}{n}} = 0.05\)</span>.</p>
<p>Hence, the 95% confidence interval is
<span class="math display">\[\pi = 0.33 \pm 1.96 * 0.05 = 0.33 \pm 0.092\]</span>
or
<span class="math display">\[(0.33-0.092, 0.33+0.092) = (0.24, 0.42)\]</span>
–</p>
<ul>
<li>How can we get a narrower confidence interval?</li>
<li>Here we computed a 95% interval, what if we want a 90% confidence interval?</li>
<li>or a 99% confidence interval?</li>
</ul>
</div>
<div id="confidence-interval-of-sample-mean" class="section level5">
<h5><span class="header-section-number">5.6.0.0.1</span> Confidence interval of sample mean</h5>
<p><span class="math display">\[
\begin{aligned}
P(-1.96 \leq \mathbf Z \leq 1.96) = 0.95 \iff \\
P(-1.96 \leq \frac{\mathbf{\bar X} - \mu}{\sigma/\sqrt{n}} \leq 1.96) = 0.95 \iff \\
P(\mathbf{\bar X} - 1.96\frac{\sigma}{\sqrt{n}} \leq \mu \leq \mathbf{\bar X} + 1.96\frac{\sigma}{\sqrt{n}}) = 0.95
\end{aligned}
\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistical-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
