<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Statistical Inference | Introduction to Biostatistics and Machine Learning</title>
  <meta name="description" content="This is the course literature for the NBIS course Introduction to Biostatistics and Machine Learning." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Statistical Inference | Introduction to Biostatistics and Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the course literature for the NBIS course Introduction to Biostatistics and Machine Learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Statistical Inference | Introduction to Biostatistics and Machine Learning" />
  
  <meta name="twitter:description" content="This is the course literature for the NBIS course Introduction to Biostatistics and Machine Learning." />
  

<meta name="author" content="NBIS" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="desc.html"/>
<link rel="next" href="multiple-testing.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>1</b> Probability theory</a><ul>
<li class="chapter" data-level="1.1" data-path="probability-theory.html"><a href="probability-theory.html#introduction-to-probability"><i class="fa fa-check"></i><b>1.1</b> Introduction to probability</a><ul>
<li class="chapter" data-level="1.1.1" data-path="probability-theory.html"><a href="probability-theory.html#random-variables"><i class="fa fa-check"></i><b>1.1.1</b> Random variables</a></li>
<li class="chapter" data-level="1.1.2" data-path="probability-theory.html"><a href="probability-theory.html#the-urn-model"><i class="fa fa-check"></i><b>1.1.2</b> The urn model</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probability-theory.html"><a href="probability-theory.html#discrete-random-variables"><i class="fa fa-check"></i><b>1.2</b> Discrete random variables</a><ul>
<li class="chapter" data-level="1.2.1" data-path="probability-theory.html"><a href="probability-theory.html#simulate-distributions"><i class="fa fa-check"></i><b>1.2.1</b> Simulate distributions</a></li>
<li class="chapter" data-level="1.2.2" data-path="probability-theory.html"><a href="probability-theory.html#parametric-discrete-distributions"><i class="fa fa-check"></i><b>1.2.2</b> Parametric discrete distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probability-theory.html"><a href="probability-theory.html#exercises"><i class="fa fa-check"></i><b>1.3</b> Exercises</a><ul>
<li class="chapter" data-level="1.3.1" data-path="probability-theory.html"><a href="probability-theory.html#introduction-to-probability-1"><i class="fa fa-check"></i><b>1.3.1</b> Introduction to probability</a></li>
<li class="chapter" data-level="1.3.2" data-path="probability-theory.html"><a href="probability-theory.html#simulation"><i class="fa fa-check"></i><b>1.3.2</b> Simulation</a></li>
<li class="chapter" data-level="1.3.3" data-path="probability-theory.html"><a href="probability-theory.html#parametric-discrete-distributions-1"><i class="fa fa-check"></i><b>1.3.3</b> Parametric discrete distributions</a></li>
<li class="chapter" data-level="1.3.4" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>1.3.4</b> Conditional probability</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probability-theory.html"><a href="probability-theory.html#continuous-random-variable"><i class="fa fa-check"></i><b>1.4</b> Continuous random variable</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probability-theory.html"><a href="probability-theory.html#parametric-continuous-distributions"><i class="fa fa-check"></i><b>1.4.1</b> Parametric continuous distributions</a></li>
<li class="chapter" data-level="1.4.2" data-path="probability-theory.html"><a href="probability-theory.html#normal-distribution"><i class="fa fa-check"></i><b>1.4.2</b> Normal distribution</a></li>
<li class="chapter" data-level="1.4.3" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>1.4.3</b> Central limit theorem</a></li>
<li class="chapter" data-level="1.4.4" data-path="probability-theory.html"><a href="probability-theory.html#chi2-distribution"><i class="fa fa-check"></i><b>1.4.4</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="1.4.5" data-path="probability-theory.html"><a href="probability-theory.html#f-distribution"><i class="fa fa-check"></i><b>1.4.5</b> F-distribution</a></li>
<li class="chapter" data-level="1.4.6" data-path="probability-theory.html"><a href="probability-theory.html#t-distribution"><i class="fa fa-check"></i><b>1.4.6</b> t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-theory.html"><a href="probability-theory.html#exercises-1"><i class="fa fa-check"></i><b>1.5</b> Exercises</a><ul>
<li class="chapter" data-level="1.5.1" data-path="probability-theory.html"><a href="probability-theory.html#normal-distribution-1"><i class="fa fa-check"></i><b>1.5.1</b> Normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="desc.html"><a href="desc.html"><i class="fa fa-check"></i><b>2</b> Descriptive statistics</a><ul>
<li class="chapter" data-level="2.1" data-path="desc.html"><a href="desc.html#data-types"><i class="fa fa-check"></i><b>2.1</b> Data types</a></li>
<li class="chapter" data-level="2.2" data-path="desc.html"><a href="desc.html#measures-of-location"><i class="fa fa-check"></i><b>2.2</b> Measures of location</a><ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#expected-value"><i class="fa fa-check"></i><b>2.2.1</b> Expected value</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="desc.html"><a href="desc.html#measures-of-spread"><i class="fa fa-check"></i><b>2.3</b> Measures of spread</a><ul>
<li class="chapter" data-level="2.3.1" data-path="desc.html"><a href="desc.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>2.3.1</b> Variance and standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="desc.html"><a href="desc.html#random-sample"><i class="fa fa-check"></i><b>2.4</b> Random sample</a><ul>
<li class="chapter" data-level="2.4.1" data-path="desc.html"><a href="desc.html#the-urn-model-to-perform-simple-random-sampling"><i class="fa fa-check"></i><b>2.4.1</b> The urn model to perform simple random sampling</a></li>
<li class="chapter" data-level="2.4.2" data-path="desc.html"><a href="desc.html#sample-properties"><i class="fa fa-check"></i><b>2.4.2</b> Sample properties</a></li>
<li class="chapter" data-level="2.4.3" data-path="desc.html"><a href="desc.html#sample-mean-and-standard-deviation"><i class="fa fa-check"></i><b>2.4.3</b> Sample mean and standard deviation</a></li>
<li class="chapter" data-level="2.4.4" data-path="desc.html"><a href="desc.html#standard-error"><i class="fa fa-check"></i><b>2.4.4</b> Standard error</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-theory.html"><a href="probability-theory.html#exercises"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>3</b> Statistical Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-test"><i class="fa fa-check"></i><b>3.1</b> Hypothesis test</a><ul>
<li class="chapter" data-level="3.1.1" data-path="statistical-inference.html"><a href="statistical-inference.html#the-null-and-alternative-hypothesis"><i class="fa fa-check"></i><b>3.1.1</b> The null and alternative hypothesis</a></li>
<li class="chapter" data-level="3.1.2" data-path="statistical-inference.html"><a href="statistical-inference.html#to-perform-a-hypothesis-test"><i class="fa fa-check"></i><b>3.1.2</b> To perform a hypothesis test</a></li>
<li class="chapter" data-level="3.1.3" data-path="statistical-inference.html"><a href="statistical-inference.html#significance-level-and-error-types"><i class="fa fa-check"></i><b>3.1.3</b> Significance level and error types</a></li>
<li class="chapter" data-level="3.1.4" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-test-simulation-examples"><i class="fa fa-check"></i><b>3.1.4</b> Hypothesis test, simulation examples</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="statistical-inference.html"><a href="statistical-inference.html#parametric-distributions"><i class="fa fa-check"></i><b>3.2</b> Parametric distributions</a><ul>
<li class="chapter" data-level="3.2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#one-sample-proportions"><i class="fa fa-check"></i><b>3.2.1</b> One sample, proportions</a></li>
<li class="chapter" data-level="3.2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#one-sample-mean"><i class="fa fa-check"></i><b>3.2.2</b> One sample, mean</a></li>
<li class="chapter" data-level="3.2.3" data-path="statistical-inference.html"><a href="statistical-inference.html#two-samples-proportions"><i class="fa fa-check"></i><b>3.2.3</b> Two samples, proportions</a></li>
<li class="chapter" data-level="3.2.4" data-path="statistical-inference.html"><a href="statistical-inference.html#two-samples-mean"><i class="fa fa-check"></i><b>3.2.4</b> Two samples, mean</a></li>
<li class="chapter" data-level="3.2.5" data-path="probability-theory.html"><a href="probability-theory.html#variance"><i class="fa fa-check"></i><b>3.2.5</b> Variance</a></li>
<li class="chapter" data-level="3.2.6" data-path="probability-theory.html"><a href="probability-theory.html#exercises"><i class="fa fa-check"></i><b>3.2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="statistical-inference.html"><a href="statistical-inference.html#point-and-interval-estimates"><i class="fa fa-check"></i><b>3.3</b> Point and interval estimates</a><ul>
<li class="chapter" data-level="3.3.1" data-path="statistical-inference.html"><a href="statistical-inference.html#bootstrap-interval"><i class="fa fa-check"></i><b>3.3.1</b> Bootstrap interval</a></li>
<li class="chapter" data-level="3.3.2" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-interval"><i class="fa fa-check"></i><b>3.3.2</b> Confidence interval</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>4</b> Multiple testing</a><ul>
<li class="chapter" data-level="4.1" data-path="multiple-testing.html"><a href="multiple-testing.html#error-types"><i class="fa fa-check"></i><b>4.1</b> Error types</a><ul>
<li class="chapter" data-level="4.1.1" data-path="multiple-testing.html"><a href="multiple-testing.html#perform-m-independent-tests"><i class="fa fa-check"></i><b>4.1.1</b> Perform <span class="math inline">\(m\)</span> independent tests:</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="multiple-testing.html"><a href="multiple-testing.html#bonferroni-correction"><i class="fa fa-check"></i><b>4.2</b> Bonferroni correction</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-testing.html"><a href="multiple-testing.html#benjamini-hochbegs-fdr"><i class="fa fa-check"></i><b>4.3</b> Benjamini-Hochbegs FDR</a></li>
<li class="chapter" data-level="4.4" data-path="multiple-testing.html"><a href="multiple-testing.html#adjusted-p-values"><i class="fa fa-check"></i><b>4.4</b> ‘Adjusted’ p-values</a></li>
<li class="chapter" data-level="4.5" data-path="multiple-testing.html"><a href="multiple-testing.html#example-10000-independent-tests-e.g.genes"><i class="fa fa-check"></i><b>4.5</b> Example, 10000 independent tests (e.g. genes)</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Biostatistics and Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-inference" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Statistical Inference</h1>
<p>Learning outcomes:</p>
<ul>
<li>to define null and alternative hypothesis</li>
<li>to perform a hypothesis test using resampling</li>
<li>to perform a t-test</li>
<li>to understand and define sampling distribution and standard error</li>
<li>to compute standard error of mean and proportions</li>
<li>to compute confidence interval of mean and proportions using the normal approximation</li>
<li>to compute confidence interval of mean using the t-distribution</li>
</ul>
<p>Statistical inference is to draw conclusions regarding properties of a population based on observations of a random sample from the population.</p>
<div id="hypothesis-test" class="section level2">
<h2><span class="header-section-number">3.1</span> Hypothesis test</h2>
<p>To perform a hypothesis test is to evaluate a hypothesis based on a random sample.</p>
<p>Typicaly, the hypotheses that are tested are assumptions about properties of the population, such as proportion, mean, mean difference, variance etc.</p>
<div id="the-null-and-alternative-hypothesis" class="section level3">
<h3><span class="header-section-number">3.1.1</span> The null and alternative hypothesis</h3>
<p>There are two hypotheses involved in a hypothesis test, the null hypothesis, <span class="math inline">\(H_0\)</span>, and the alternative hypothesis, <span class="math inline">\(H_1\)</span>.</p>
<p>The null hypothesis is in general neutral, “no change”, “no difference between groups”, “no association”. In general we want to show that <span class="math inline">\(H_0\)</span> is false.</p>
<p>The alternative hypothesis expresses what the researcher is interested in “the treatment has an effect”, “there is a difference between groups”, “there is an association”. The alternative hypothesis can also be directional “the treatment has a positive effect”.</p>
</div>
<div id="to-perform-a-hypothesis-test" class="section level3">
<h3><span class="header-section-number">3.1.2</span> To perform a hypothesis test</h3>
<ol style="list-style-type: decimal">
<li>Define <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span></li>
<li>Select appropriate test statistic, <span class="math inline">\(T\)</span>, and compute the observed value, <span class="math inline">\(t_{obs}\)</span></li>
<li>Assume that the <span class="math inline">\(H_0\)</span> is true and compute the sampling distribution of <span class="math inline">\(T\)</span>.</li>
<li>Select an appropriate significance level, <span class="math inline">\(\alpha\)</span></li>
<li>Compare the observed value, <span class="math inline">\(t_{obs}\)</span>, with the computed sampling distribution under <span class="math inline">\(H_0\)</span> and compute a p-value. The p-value is the probability of observing a value at least as extreme as the observed value, if <span class="math inline">\(H_0\)</span> is true.</li>
<li>Based on the p-value either accept or reject <span class="math inline">\(H_0\)</span>.</li>
</ol>

<div class="definition">
<p><span id="def:samplingdistribution" class="definition"><strong>Definition 3.1  </strong></span><strong>Sampling distribution</strong></p>
A sampling distribution is the distribution of a statistic of a large number of samples drawn from a specific population.
</div>


<div class="definition">
<p><span id="def:nulldistribution" class="definition"><strong>Definition 3.2  </strong></span><strong>Null distribution</strong></p>
The null distribution is a sampling distribution when the null hypothesis is true.
</div>

<div class="figure" style="text-align: center"><span id="fig:examplenull"></span>
<img src="biostatbook_files/figure-html/examplenull-1.png" alt="A null distribution" width="70%" />
<p class="caption">
Figure 3.1: A null distribution
</p>
</div>

<div class="definition">
<p><span id="def:pvalue" class="definition"><strong>Definition 3.3  </strong></span><strong>p-value</strong></p>
The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.
</div>

<div class="figure" style="text-align: center"><span id="fig:examplepval"></span>
<img src="biostatbook_files/figure-html/examplepval-1.png" alt="The p-value is the probability to observe $x_{obs}$ or something more extreme, if the null hypothesis is true." width="70%" /><img src="biostatbook_files/figure-html/examplepval-2.png" alt="The p-value is the probability to observe $x_{obs}$ or something more extreme, if the null hypothesis is true." width="70%" />
<p class="caption">
Figure 3.2: The p-value is the probability to observe <span class="math inline">\(x_{obs}\)</span> or something more extreme, if the null hypothesis is true.
</p>
</div>
</div>
<div id="significance-level-and-error-types" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Significance level and error types</h3>
<table>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
H0 is true
</td>
<td style="text-align:left;">
H0 is false
</td>
</tr>
<tr>
<td style="text-align:left;">
Accept H0
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Type II error, miss
</td>
</tr>
<tr>
<td style="text-align:left;">
Reject H0
</td>
<td style="text-align:left;">
Type I error, false alarm
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p>The significance level, <span class="math inline">\(\alpha\)</span> = P(false alarm) = P(Reject <span class="math inline">\(H_0\)</span>|<span class="math inline">\(H_0\)</span> is true).</p>
<p>The significance level is the risk to of false alarm, i.e. to say “I have a hit”, “I found a difference”, when the the null hypothesis (“there is no difference”) is true. The risk of false alarm is controll by setting the significance level to a disired value. We do want to keep the risk of false alarm (type I error) low, but at the same time we don’t want to many missed hits (type II error).</p>
<p>The significance level should be set before the hypothesis test is performed. Common values to use are 0.05 or 0.01.</p>
<p>If the p-value is above the significance level, <span class="math inline">\(H_0\)</span> is accepted.</p>
<p>If the p-value is below the significance level, <span class="math inline">\(H_0\)</span> is rejected.</p>
<!-- Power = P(Refect H0|H0 is false) -->
</div>
<div id="hypothesis-test-simulation-examples" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Hypothesis test, simulation examples</h3>
<p>In these examples the significance level is set to 0.05.</p>

<div class="example">
<p><span id="exm:simpollentest" class="example"><strong>Example 3.1  (Simulation example)  </strong></span><strong>Pollen allergy</strong></p>
<p>Let’s assume we know that the proportion of pollen allergy in Sweden is <span class="math inline">\(0.3\)</span>. We suspect that the number of pollen allergic has increased in Uppsala in the last couple of years and want to investigate this.</p>
Observe 100 people from Uppsala, 42 of these were allergic to pollen. Is there a reason to believe that the proportion of pollen allergic in Uppsala <span class="math inline">\(\pi &gt; 0.3\)</span>?
</div>

<div id="null-and-alternative-hypotheses" class="section level5 unnumbered">
<h5>Null and alternative hypotheses</h5>
<p><span class="math inline">\(H_0:\)</span> The proportion of pollen allergy in Uppsala is the same as in Sweden as a whole.</p>
<p><span class="math inline">\(H_1:\)</span> The proportion of pollen allergy in Uppsala is not the same as in Sweden as a whole.</p>
<p>or expressed differently;</p>
<p><span class="math display">\[H_0:\, \pi=\pi_0\]</span></p>
<p><span class="math display">\[H_1:\, \pi&gt;\pi_0\]</span>
where <span class="math inline">\(\pi\)</span> is the unknown proportion of pollen allergy in the Uppsala population that. <span class="math inline">\(\pi_0 = 0.3\)</span> is the proportion of pollen allergy in Sweden.</p>
</div>
<div id="test-statistic" class="section level5 unnumbered">
<h5>Test statistic</h5>
<p>Here we are interested in the proportion of pollen allergic in Uppsala. An appropriate test statistic could be the number of pollen allergic in a sample of size <span class="math inline">\(n=100\)</span>, <span class="math inline">\(X\)</span>. As an alternative we can use the proportion of pollen allergic in a sample of size <span class="math inline">\(n\)</span>,</p>
<p><span class="math display">\[P = \frac{X}{n}\]</span></p>
<p>Let’s use <span class="math inline">\(P\)</span> as our test statistic and compute the observed value, <span class="math inline">\(p_{obs}\)</span>. In our sample of 100 people from Uppsala the proportion allergic to pollen is <span class="math inline">\(p=42/100=0.42\)</span>.</p>
</div>
<div id="null-distribution" class="section level5 unnumbered">
<h5>Null distribution</h5>
<p>The sampling distribution of <span class="math inline">\(P\)</span> under <span class="math inline">\(H_0\)</span> (i.e. when the null hypothesis is true) is what we call the null distribution.</p>
<p><span class="math inline">\(H_0\)</span> state that <span class="math inline">\(\pi=0.3\)</span>. We can model this using an urn model as follows;</p>
<div class="figure" style="text-align: center"><span id="fig:pollenurn"></span>
<img src="figures/pollenurn.png" alt="An urn model of the null hypothesis $\pi=0.3$. The black balls represent allergic and the white balls non-allergic." width="20%" />
<p class="caption">
Figure 3.3: An urn model of the null hypothesis <span class="math inline">\(\pi=0.3\)</span>. The black balls represent allergic and the white balls non-allergic.
</p>
</div>
<p>Using this model, we can simulate taking a sample of size 100 many times.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co">## Urn</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>##  [1] 0 0 0 0 0 0 0 1 1 1</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="co">## Sample 100 times with replacement</span></a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="kw">sample</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>)), <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##   [1] 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0
##  [38] 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0
##  [75] 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="co">## Compute proportion of samples that are allergic (1)</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2"><span class="kw">sum</span>(<span class="kw">sample</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>)), <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>))<span class="op">/</span><span class="dv">100</span></a></code></pre></div>
<pre><code>## [1] 0.34</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="co">## Draw samples of size 100 and compute proporion allergic 100000 times</span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2">p &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100000</span>, <span class="kw">mean</span>(<span class="kw">sample</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">3</span>)), <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)))</a></code></pre></div>
<p>Finally plot the distribution</p>
<div class="figure" style="text-align: center"><span id="fig:pollensampledistr"></span>
<img src="biostatbook_files/figure-html/pollensampledistr-1.png" alt="The sampling distribution." width="45%" />
<p class="caption">
Figure 3.4: The sampling distribution.
</p>
</div>
</div>
<div id="compute-p-value" class="section level5 unnumbered">
<h5>Compute p-value</h5>
<p>Compare the observed value, <span class="math inline">\(p_{obs} = 0.42\)</span> to the null distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="biostatbook_files/figure-html/unnamed-chunk-17-1.png" alt="The sampling distribution. The observed value is marked by a red vertical line." width="50%" />
<p class="caption">
Figure 3.5: The sampling distribution. The observed value is marked by a red vertical line.
</p>
</div>
<p>The p-value is the probability of getting the observed value or higher, if the null hypothesis is true.</p>
<p>Use the null distribution to calculate the p-value, <span class="math inline">\(P(P \geq 0.42|H_0)\)</span>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="co">## How many times </span></a>
<a class="sourceLine" id="cb26-2" data-line-number="2"><span class="kw">sum</span>(p <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.42</span>)</a></code></pre></div>
<pre><code>## [1] 711</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="co">## p-value</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2"><span class="kw">sum</span>(p <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.42</span>)<span class="op">/</span><span class="kw">length</span>(p)</a></code></pre></div>
<pre><code>## [1] 0.0071</code></pre>
<p>p = <span class="math inline">\(P(P \geq 0.42|H_0)\)</span> = 0.00711</p>
</div>
<div id="accept-or-reject-h_0" class="section level5 unnumbered">
<h5>Accept or reject <span class="math inline">\(H_0\)</span>?</h5>

<div class="example">
<p><span id="exm:permutationtest" class="example"><strong>Example 3.2  (Permutation test)  </strong></span><strong>Do high fat diet lead to increased body weight?</strong></p>
<p>Study setup:</p>
<ol style="list-style-type: decimal">
<li>Order 24 female mice from a lab.</li>
<li>Randomly assign 12 of the 24 mice to receive high-fat diet, the
remaining 12 are controls (ordinary diet).</li>
<li>Measure body weight after one week.
</div></li>
</ol>
</div>
<div id="null-and-alternative-hypotheses-1" class="section level5 unnumbered">
<h5>Null and alternative hypotheses</h5>
<p><span class="math display">\[
\begin{aligned}
H_0: \mu_2 = \mu_1 \iff \mu_2 - \mu_1 = 0\\
H_1: \mu_2&gt;\mu_1 \iff \mu_2-\mu_1 &gt; 0
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mu_2\)</span> is the (unknown) mean body weight of the high-fat mouse population and <span class="math inline">\(\mu_1\)</span> is the mean body-weight of the control mouse population.</p>
<p>Studied population: Female mice that can be ordered from a lab.</p>
</div>
<div id="test-statistic-1" class="section level5 unnumbered">
<h5>Test statistic</h5>
<p>Here we are interested in the mean difference between high-fat and control mice.</p>
<p>Mean weight of 12 (randomly selected) mice on ordinary diet, <span class="math inline">\(\bar X_1\)</span>. <span class="math inline">\(E[\bar X_1] = E[X_1] = \mu_1\)</span></p>
<p>Mean weight of 12 (randomly selected) mice on high-fat diet, <span class="math inline">\(\bar X_2\)</span>. <span class="math inline">\(E[\bar X_2] = E[X_2] = \mu_2\)</span></p>
<p>The mean difference is also a random variable: <span class="math inline">\(D = \bar X_2 - \bar X_1\)</span></p>
<p>The observed values, mouse weights in grams, are summarized below;</p>
<table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
high-fat
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
39
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
32
</td>
</tr>
<tr>
<td style="text-align:left;">
ordinary
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
24
</td>
</tr>
</tbody>
</table>
<p>Mean weight of control mice (ordinary diet): <span class="math inline">\(\bar x_1 = 25.83\)</span></p>
<p>Mean weight of mice on high-fat diet: <span class="math inline">\(\bar x_2 = 28.00\)</span></p>
<p>Difference in mean weights: <span class="math inline">\(d_{obs} = \bar x_2 - \bar x_1 = 2.17\)</span></p>
</div>
<div id="null-distribution-1" class="section level5 unnumbered">
<h5>Null distribution</h5>
<p>If high-fat diet has no effect, i.e. if <span class="math inline">\(H_0\)</span> was true, the result would be as if all mice were given the same diet. What can we expect if all mice are fed with the same type of food?</p>
<p>This can be accomplished using permutation</p>
<p>The 24 mice were initially from the same population, depending on how the mice are randomly assigned to high-fat and normal group, the mean weights would differ, even if the two groups were treated the same.</p>
<p>Assume <span class="math inline">\(H_0\)</span> is true, i.e. assume all mice are equivalent and</p>
<ol style="list-style-type: decimal">
<li>Randomly reassign 12 of the 24 mice to ‘high-fat’ and the remaining 12 to ‘control’.</li>
<li>Compute difference in mean weights</li>
</ol>
<p>If we repeat 1-2 many times we get the sampling distribution when <span class="math inline">\(H_0\)</span> is true, the so called null distribution, of difference in mean weights.</p>
<p><img src="biostatbook_files/figure-html/permtest-1.png" width="50%" /></p>
</div>
<div id="compute-p-value-1" class="section level5 unnumbered">
<h5>Compute p-value</h5>
<p>What is the probability to get an at least as extreme mean difference as our observed value, <span class="math inline">\(d_{obs}\)</span>, if <span class="math inline">\(H_0\)</span> was true?</p>
<p>$P(X_2 - X_2 d_{obs} | H_0) = $0.126</p>
<p>Conclusion?</p>
<!-- ## Parametric hypothesis tests -->
</div>
</div>
</div>
<div id="parametric-distributions" class="section level2">
<h2><span class="header-section-number">3.2</span> Parametric distributions</h2>
<p>In previous chapters we have computed the sampling distribution using resampling techniques to be able to perform hypothesis tests or compute interval estimates. If the null distribution was already known (or could be computed based on a few assumptions) resampling would not be necessary.</p>
<p>We can follow the same steps as before to perform a hypothesis test:</p>
<ol style="list-style-type: decimal">
<li>Define <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span></li>
<li>Select appropriate test statistic, <span class="math inline">\(T\)</span>, and compute the observed value, <span class="math inline">\(t_{obs}\)</span></li>
<li>Assume that the <span class="math inline">\(H_0\)</span> and derive the null distribution of the test statistic based on appropriate assumptions.</li>
<li>Select an appropriate significance level, <span class="math inline">\(\alpha\)</span></li>
<li>Compare the observed value, <span class="math inline">\(t_{obs}\)</span>, with the null distribution and compute a p-value. The p-value is the probability of observing a value at least as extreme as the observed value, if <span class="math inline">\(H_0\)</span> is true.</li>
<li>Based on the p-value either accept or reject <span class="math inline">\(H_0\)</span>.</li>
</ol>
<div id="one-sample-proportions" class="section level3">
<h3><span class="header-section-number">3.2.1</span> One sample, proportions</h3>

<div class="example">
<p><span id="exm:parampollen" class="example"><strong>Example 3.3  </strong></span><strong>Let’s get back to the pollen example!</strong></p>
Assume that the proportion of pollen allergy in Sweden is known to be <span class="math inline">\(0.3\)</span>. Observe 100 people from Uppsala, 42 of these were allergic to pollen. Is there a reason to believe that the proportion of pollen allergic in Uppsala <span class="math inline">\(\pi &gt; 0.3\)</span>?
</div>

<p>The number of allergic individuals in a sample of size <span class="math inline">\(n\)</span> is <span class="math inline">\(X\)</span> and the proportion of allergic persons is <span class="math inline">\(P = X/n\)</span>. <span class="math inline">\(X\)</span> is binomially distributed, but here we can use the Central limit theorem, see <a href="probability-theory.html#thm:CLT">1.1</a>.</p>

<div class="theorem">
<span id="thm:CLTrep" class="theorem"><strong>Theorem 3.1  </strong></span>The sum of <span class="math inline">\(n\)</span> independent and equally distributed random variables
is normally distributed, if <span class="math inline">\(n\)</span> is large enough.
</div>

<p>As a result of the central limit theorem, the distribution of number or proportion of allergic
individuals in a sample of size <span class="math inline">\(n\)</span> is approximately normal. At least if the sample is large enough. A rule of thumb is that the sample size should be <span class="math inline">\(n&gt;30\)</span>.</p>
<p>Here, the sample size is 100!</p>
<p>The normal distribution has two parameters, mean and standard deviation.</p>
<p>From the binomial distribution we know that <span class="math inline">\(E[X] = \pi\)</span> and <span class="math inline">\(var(X) = n\pi(1-\pi)\)</span>. Hence <span class="math inline">\(E[P] = \pi\)</span> and <span class="math inline">\(var(P) = \frac{\pi(1-\pi)}{n}\)</span>.</p>
<p>The standard error is thus</p>
<p><span class="math display">\[SE=\sqrt{\frac{\pi(1-\pi)}{n}}\]</span></p>
<p>When the null hypothesis is true <span class="math inline">\(\pi\)</span> is known and <span class="math inline">\(\pi=0.3\)</span>.</p>
<p>Actually these calculations are true in general when a proportion in one sample is compared to a known value.</p>
<p><span class="math display">\[H_0: \pi=\pi_0 \\
H_1: \pi&gt;\pi_0 \]</span></p>
<p>Ather potential alternative hypothesis are <span class="math inline">\(H_1: \pi&lt;\pi_0\)</span> or <span class="math inline">\(H_1:\pi \neq \pi_0\)</span>, but in this particular xample we are only interested in the alternative that <span class="math inline">\(\pi &gt; \pi_0\)</span>.</p>
<p>If <span class="math inline">\(H_0\)</span> is true <span class="math inline">\(\pi=\pi_0\)</span> and</p>
<p><span class="math display">\[P \sim N\left(\pi_0, \sqrt{\frac{\pi_0(1-\pi_0)}{n}}\right)\]</span>
An appropriate test statistic is</p>
<p><span class="math display">\[Z = \frac{P-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}\]</span></p>
<p><span class="math inline">\(Z \in N(0,1)\)</span> which makes probabilities easy to compute.</p>
<p>Back to our example, replace <span class="math inline">\(P\)</span> with our observed value <span class="math inline">\(p=0.42\)</span> and <span class="math inline">\(\pi_0=0.3\)</span> and compute our observed</p>
<p><span class="math display">\[Z_{obs} = \frac{0.42-0.3}{\sqrt{\frac{0.3(1-0.3)}{100}}} = 2.62\]</span></p>
<p>The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true. If the computed probability is below <span class="math inline">\(\alpha=0.05\)</span> our significance threshold, <span class="math inline">\(H_0\)</span> will be rejected.</p>
<p><span class="math display">\[p = P(P&gt;\pi_0) = P(Z&gt;Z_{obs}) = P(Z&gt;2.62) = 1 - P(Z \leq 2.62) = [table] = 1 - 0.996 = 0.0044\]</span></p>
<p>As 0.0044&lt;0.05 we reject <span class="math inline">\(H_0\)</span> and conclude that there is reason to believe that the proportion of allergic in Uppsala is greater than 0.3.</p>
</div>
<div id="one-sample-mean" class="section level3">
<h3><span class="header-section-number">3.2.2</span> One sample, mean</h3>
<p>A one sample test of means compares the mean of a sample to a prespecified value.</p>
<p>For example, we might know that the weight of a mouse on normal diet is normally distributed with mean 24.0 g and standard deviation 3 g and want to compare the weight of a sample of 10 mice on high-fat diet to the known mean value for mice on normal diet.</p>
<p>The hypotheses:</p>
<p><span class="math display">\[
H_0: \mu = \mu_0 \\
H_1: \mu \neq \mu_0\]</span></p>
<p>The alternative hypothesis, <span class="math inline">\(H_1,\)</span> above is for the two sided hypothesis test. Other options are the one sided <span class="math inline">\(H_1\)</span>; <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span> or <span class="math inline">\(H_1: \mu &lt; \mu_0\)</span>.</p>
<p>If <span class="math display">\[X \sim N(\mu, \sigma)\]</span> (this could for example be the weight of a mouse on high-fat diet) then the sample mean <span class="math display">\[\bar X \sim N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)\]</span>.</p>
<p>If <span class="math inline">\(\sigma\)</span> is known the test statistic</p>
<p><span class="math display">\[Z = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}}\]</span>
is normally distributed, <span class="math inline">\(\sim N(0,1)\)</span>.</p>
<p>For small <span class="math inline">\(n\)</span> and unknown <span class="math inline">\(\sigma\)</span>, the test statistic</p>
<p><span class="math display">\[t = \frac{\bar X - \mu}{\frac{s}{\sqrt{n}}}\]</span></p>
<p>is t-distributed with <span class="math inline">\(df=n-1\)</span> degrees of freedom.</p>
</div>
<div id="two-samples-proportions" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Two samples, proportions</h3>
<p><span class="math display">\[H_0: \pi_1 - \pi_2 = 0\\
H_1: \pi_1 - \pi_2 \neq 0\]</span></p>
<p>Alternatively, a one sided alternative hypothesis can be used; <span class="math inline">\(H_1: \pi_1 - \pi_2 &gt;0\)</span> or <span class="math inline">\(H_1: \pi_1 - \pi_2 &lt; 0\)</span>.
<!-- If $H_0$ is true --></p>
<!-- $$P_1 - P_2 \sim N\left(0, \sqrt{\pi(1-\pi)\left (\frac{1}{n_1} + \frac{1}{n_2}\right)} \right)$$ -->
<!-- where $\pi$ is the  -->
<p>Test statistic</p>
<p><span class="math display">\[Z = \frac{P_1 - P_2}{\sqrt{P(1-P)\left (\frac{1}{n_1} + \frac{1}{n_2}\right)}}\]</span></p>
<p>where <span class="math inline">\(P\)</span> is the proportion in the merged sample of size <span class="math inline">\(n_1 + n_2\)</span>. <span class="math inline">\(Z \in N(0,1)\)</span> and p-value can be computed using the standard normal distribution.</p>
</div>
<div id="two-samples-mean" class="section level3">
<h3><span class="header-section-number">3.2.4</span> Two samples, mean</h3>
<p>A two sample test of means is used to determine if two population means are equal.</p>
<p>Two independent samples are collected (one from each population) and the means are compared. Can for example be used to determine if a treatment group is different compared to a control group, in terms of the mean of a property of interest.</p>
<p>The null hypothesis;</p>
<p><span class="math display">\[H_0: \mu_2 = \mu_1\]</span>
The alternative hypothesis can either be two sided</p>
<p><span class="math display">\[H_1: \mu_2 \neq \mu_1\]</span>
or one sided</p>
<p><span class="math display">\[H_1: \mu_2 &gt; \mu_1\]</span>
or</p>
<p><span class="math display">\[H_1: \mu_2 &lt; \mu_1\]</span></p>
<p>Assume that observations from both populations are normally distributed;</p>
<p><span class="math display">\[
\begin{aligned}
X_1 \sim N(\mu_1, \sigma_1) \\
X_2 \sim N(\mu_2, \sigma_2)
\end{aligned}
\]</span>
Then it follows that the sample means will also be normally distributed;</p>
<p><span class="math display">\[
\begin{aligned}
\bar X_1 \sim N(\mu_1, \sigma_1/\sqrt{n_1}) \\
\bar X_2 \sim N(\mu_2, \sigma_2/\sqrt{n_2})
\end{aligned}
\]</span></p>
<p>The mean difference <span class="math inline">\(D = \bar X_2 - \bar X_1\)</span> is thus also normally distributed:</p>
<p><span class="math display">\[D = \bar X_2 - \bar X_1 = N\left(\mu_2-\mu_1, \sqrt{\frac{\sigma_2^2}{n_2} + \frac{\sigma_1^2}{n_1}}\right)\]</span></p>
<p>If <span class="math inline">\(H_0\)</span> is true: <span class="math display">\[D = \bar X_2 - \bar X_1 = N\left(0, \sqrt{\frac{\sigma_2^2}{n_2} + \frac{\sigma_1^2}{n_1}}\right)\]</span></p>
<p>The test statistic: <span class="math display">\[Z = \frac{\bar X_2 - \bar X_1}{\sqrt{\frac{\sigma_2^2}{n_2} + \frac{\sigma_1^2}{n_1}}}\]</span> is standard normal, i.e. <span class="math inline">\(Z \sim N(0,1)\)</span>.</p>
<p>However, note that the test statistic require the standard deviations <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> to be known.</p>
<p>What if the population standard deviations are not known?</p>
<p>If the sample sizes are large, we can replace the known standard deviations with our sample standard deviations and according to the central limit theorem assume that</p>
<p><span class="math display">\[Z = \frac{\bar X_2 - \bar X_1}{\sqrt{\frac{s_2^2}{n_2} + \frac{s_1^2}{n_1}}} \sim N(0,1)\]</span></p>
<p>and proceed as before.</p>
<!-- Here $n_1=n_2=12$ which is not very large. -->
<p>For small sample sizes the test statistic will be t-distributed.</p>
<p><span class="math display">\[t = \frac{\bar X_2 - \bar X_1}{\sqrt{\frac{s_2^2}{n_2} + \frac{s_1^2}{n_1}}}\]</span></p>
<p>For small sample sizes we can use Student’s t-test, which requires us to assume that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> both are normally distributed and have equal variances. With these assumptions we can compute the pooled variance</p>
<p><span class="math display">\[
s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}
\]</span></p>
<p>and the test statistic</p>
<p><span class="math display">\[t = \frac{\bar X_1 - \bar X_2}{\sqrt{s_p^2(\frac{1}{n_1} + \frac{1}{n_2})}}\]</span></p>
<p><span class="math inline">\(t\)</span> is t-distributed with <span class="math inline">\(n_1+n_2-2\)</span> degrees of freedom.</p>
<p>The t-test is implemented in R, e.g. in the function <code>t.test</code> in the R-package <code>stats</code>, both Student’s t-test with equal variances and Welch’s t-test with unequal variances.</p>
</div>
<div id="variance" class="section level3">
<h3><span class="header-section-number">3.2.5</span> Variance</h3>
<p>The test of equal variance in two groups is based on the null hypothesis</p>
<p><span class="math display">\[H_0: \sigma_1^2 = \sigma_2^2\]</span></p>
<p>If the two samples both come from two populations with normal distributions, the sample variances</p>
<p><span class="math display">\[S_1^2 = \frac{1}{n_1-1} \sum_{i=1}^{n_1} (X_{1i}-\bar X_1)^2\\
S_2^2 = \frac{1}{n_2-1} \sum_{i=1}^{n_2} (X_{2i}-\bar X_2)^2\]</span></p>
<p>It can be shown that <span class="math inline">\(\frac{(n_1-1)S_1^2}{\sigma_1^2} ~ \chi^2(n_1-1)\)</span> and <span class="math inline">\(\frac{(n_2-1)S_2^2}{\sigma_2^2} ~ \chi^2(n_2-1)\)</span>.</p>
<p>Hence, the test statistic for comparing the variances of two groups</p>
<p><span class="math display">\[F = \frac{S_1^2}{S_2^2}\]</span>
is <span class="math inline">\(F\)</span> is F-distributed with <span class="math inline">\(n_1-1\)</span> and <span class="math inline">\(n_2-1\)</span> degrees of freedom.</p>
<p>In R a test of equal variances can be performred using the function <code>var.test</code>.</p>
</div>
<div id="exercises" class="section level3">
<h3><span class="header-section-number">3.2.6</span> Exercises</h3>

<div class="exercise">
<span id="exr:Hb" class="exercise"><strong>Exercise 3.1  </strong></span>The hemoglobin value (Hb) in women is on average 140 g/L. You observe the following Hb values in a set of five men: 154, 140, 147, 162, 172. Assume that Hb is normally distributed. Is there a reason to believe that the mean Hb value in men differ from that in women?
</div>


<div class="exercise">
<span id="exr:mice12" class="exercise"><strong>Exercise 3.2  </strong></span>In order to study the effect of high-fat diet 12 mice are fed normal diet (control group) and 12 mice are fed high-fat diet. After a couple of weeks the mouse weights in gram are recorded;
</div>

<table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
high-fat
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
39
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
32
</td>
</tr>
<tr>
<td style="text-align:left;">
ordinary
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
24
</td>
</tr>
</tbody>
</table>
<p>Does high fat diet increase body weight in mice?</p>
<ol style="list-style-type: lower-alpha">
<li>Assume equal variances.</li>
</ol>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="co"># Student&#39;s t-test with pooled variances</span></a>
<a class="sourceLine" id="cb30-2" data-line-number="2"><span class="kw">t.test</span>(xHF, xN, <span class="dt">var.equal=</span><span class="ot">TRUE</span>, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Don’t assume equal variances.</li>
</ol>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="co"># Unequal variances with Welch approximation to the degrees of freedom (the default)</span></a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw">t.test</span>(xHF, xN, <span class="dt">var.equal=</span><span class="ot">FALSE</span>, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<!-- Exercise, known $\sigma$ -->
<!-- If the means of the populations are unknown, but the standard variations are known -->
<!-- Let's assume that both mouse body weights in control and treatment groups are independent and normally distributed, with unknown mean, but known standard deviations, $\sigma_1=3.4$ and $\sigma_2=5.1$. -->
<!-- ```{r echo=F, eval=FALSE} -->
<!-- ## Our observed value -->
<!-- dobs -->
<!-- ## The p-value -->
<!-- 1-pnorm(dobs, mean=0, sd=sqrt(5.1^2/12 + 3.4^2/12)) -->
<!-- 1-pnorm((dobs-0)/sqrt(5.1^2/12 + 3.4^2/12)) -->
<!-- pnorm(dobs, mean=0, sd=sqrt(5.1^2/12 + 3.4^2/12), lower.tail=FALSE) -->
<!-- pnorm((dobs-0)/sqrt(5.1^2/12 + 3.4^2/12), lower.tail=FALSE) -->
<!-- ``` -->
</div>
</div>
<div id="point-and-interval-estimates" class="section level2">
<h2><span class="header-section-number">3.3</span> Point and interval estimates</h2>
<p>As seen in previous chapter, the sample proportion or mean is an unbiased estimate of the population values. When we only have a sample, the sample estimate will be our best guess of the population value, but it will not be without error.</p>
<p>If we are interested in how large proportion of the Uppsala population is allergic to pollen, we can investigate this by studying a random sample. Randomly select 100 persons in Uppsala. It is important to actually sample randomly, ideally every individual should have the same probability of being sampled.</p>
<p>In our sample, we observe that 42 of the 100 has a pollen allergy. Hence, the observed sample proportion is <span class="math inline">\(p=0.42\)</span>.</p>
<!-- What does this say about the population proportion $\pi$? -->
<p>Based on this observation our point estimate of the Uppsla popultation proportion <span class="math inline">\(\pi\)</span> is <span class="math inline">\(\pi \approx p = 0.42\)</span>. We know that there is a certain uncertainty in this measurement, if the experiment is repeated we would select 100 other persons and our point estimate would be slihtly different.</p>
<div id="bootstrap-interval" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Bootstrap interval</h3>
<p>Using bootstrap we can sample with replacement from our sample to estimate the uncertainty.</p>
<p>Bootstrap is to use the data we have (our sample) and sample repeatedly with replacement from this data.</p>
<p>Put the entire sample in an urn!</p>
<div class="figure" style="text-align: center"><span id="fig:pollenurn42"></span>
<img src="figures/pollenurn42.png" alt="An urn model with 42 allergy (black) and 58 non-allergy (white). The black balls represent allergic and the white balls non-allergic." width="20%" />
<p class="caption">
Figure 3.6: An urn model with 42 allergy (black) and 58 non-allergy (white). The black balls represent allergic and the white balls non-allergic.
</p>
</div>
<p>Sample from the urn with replacement to compute the bootstrap distribution.</p>
<p><img src="biostatbook_files/figure-html/CIboot-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Using the bootstrap distribution the uncertainty of our estimate of <span class="math inline">\(\pi\)</span> can be estimated.</p>
<p>The 95% bootstrap interval is [0.24, 0.42].</p>
<p>The bootstrap is very useful if you do not know the distribution of our sampled propery. But in our example we actually do.</p>
</div>
<div id="confidence-interval" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Confidence interval</h3>
<p>A confidence interval is a type of interval estimate associated with a confidence level.</p>
<div id="confidence-interval-of-proportions" class="section level4">
<h4><span class="header-section-number">3.3.2.1</span> Confidence interval of proportions</h4>
<p>Remember that we can use the central limit theorem to show that</p>
<p><span class="math display">\[P \sim N\left(\pi, SE\right) \iff P \sim \left(\pi, \sqrt{\frac{\pi(1-\pi)}{n}}\right)\]</span></p>
<p>It follows that</p>
<p><span class="math display">\[Z = \frac{P - \pi}{SE} \sim N(0,1)\]</span>
Based on what we know of the standard normal distribution, we can compute an interval around the population property <span class="math inline">\(\pi\)</span> such that the probability that a sample property <span class="math inline">\(p\)</span> fall within this interval is <span class="math inline">\(1-\alpha\)</span>.</p>
<p><span class="math display">\[P(-z &lt; \frac{P - \pi}{SE} &lt; z) = 1 - \alpha\]</span>
For a 95% confidence interval z=1.96 (from a table of the standard normal distribution). Other confidence levels of interest include 90% (z=1.64) and 99% (z=2.58).</p>
<p><span class="math display">\[P\left(-z &lt; \frac{P-\pi}{SE}&lt;z\right) = \left(-z &lt; Z &lt;z\right) = 1-\alpha\]</span>
We can rewrite this to</p>
<p><span class="math display">\[P\left(\pi-z SE &lt; P &lt; \pi + z SE\right) = 1-\alpha\]</span>
in other words sample fraction <span class="math inline">\(p\)</span> will fall between <span class="math inline">\(\pi \pm 1.96 SE\)</span> with 95% probability.</p>
<p>The equation can also be rewritten to
<span class="math display">\[P\left(P-z SE &lt; \pi &lt; P + z SE\right) = 1 - \alpha\]</span>
The observed confidence interval is what we get when we replace the random variable <span class="math inline">\(P\)</span> with our observed fraction,</p>
<p><span class="math display">\[p-z SE &lt; \pi &lt; p + z SE\]</span>
<span class="math display">\[\pi = p \pm z SE = p \pm z \sqrt{\frac{p(1-p)}{n}}\]</span>
The 95% confidence interval <span class="math display">\[\pi = p \pm 1.96 \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<p>A 95% confidence interval will have 95% chance to cover the true value.</p>
<p><img src="biostatbook_files/figure-html/CIallergy-1.png" width="4200" /></p>
<p>Back to our example of proportion pollen allergic in Uppsala. <span class="math inline">\(p=0.33\)</span> and <span class="math inline">\(SE=\sqrt{\frac{p(1-p)}{n}} = 0.05\)</span>.</p>
<p>Hence, the 95% confidence interval is
<span class="math display">\[\pi = 0.33 \pm 1.96 * 0.05 = 0.33 \pm 0.092\]</span>
or
<span class="math display">\[(0.33-0.092, 0.33+0.092) = (0.24, 0.42)\]</span></p>

<div class="exercise">
<span id="exr:CIprop" class="exercise"><strong>Exercise 3.3  </strong></span>a) How can we get a narrower confidence interval?
b) Here we computed a 95% interval, what if we want a 90% confidence interval?
c) or a 99% confidence interval?
</div>

<div id="confidence-interval-of-mean" class="section level5">
<h5><span class="header-section-number">3.3.2.1.1</span> Confidence interval of mean</h5>
<p>The confidence interval of mean can be derived similarly.</p>
<p>The mean of a sample of <span class="math inline">\(n\)</span> independent and identically normal distributed observations <span class="math inline">\(X_i\)</span> is normally distributed;</p>
<p><span class="math display">\[\bar X \sim N(\mu, \frac{\sigma}{\sqrt{n}})\]</span></p>
<p>If <span class="math inline">\(\sigma\)</span> is unknown the statistic</p>
<p><span class="math display">\[\frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} \sim t(n-1)\]</span>
is t-distributed with <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
<p>It follows that</p>
<p><span class="math display">\[
\begin{aligned}
P\left(-t &lt; \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} &lt; t\right) = 1 - \alpha \iff \\
P\left(\bar X - t \frac{\sigma}{\sqrt{n}} &lt; \mu &lt; \bar X + t \frac{\sigma}{\sqrt{n}}\right) = 1 - \alpha
\end{aligned}
\]</span></p>
<p>The confidence interval with confidence level <span class="math inline">\(1-\alpha\)</span> is thus;</p>
<p><span class="math display">\[\mu = \bar x \pm t \frac{s}{\sqrt{n}}\]</span></p>
<p>For a 95% confidence interval and <span class="math inline">\(n=5\)</span> <span class="math inline">\(t\)</span> is 2.78.</p>
<p>The <span class="math inline">\(t\)</span> values for different values of <span class="math inline">\(\alpha\)</span> and degrees of freedom are tabulated and can be computed in R using the function <code>qt</code>.</p>
<pre><code>## [1] 2.8</code></pre>

<div class="exercise">
<span id="exr:CIm1" class="exercise"><strong>Exercise 3.4  </strong></span>You measure the Hb value in 10 50 year old men and get the following observations; 145, 165, 134, 167, 158, 176, 156, 189, 143, 123. Compute a 95% confidence interval for the mean Hb value.
</div>


</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="desc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
